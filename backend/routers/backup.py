from fastapi import APIRouter, HTTPException, Query, Body, Depends
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
import logging
import os

from database import get_database, SessionLocal, ScheduleService, Schedule

router = APIRouter()
logger = logging.getLogger(__name__)

# Constants (should be imported from main)
SCHEDULES_DATA_DIR = 'data'
from constants import BACKUP_RETENTION_DAYS


# Helper Functions
def get_file_size_mb(file_path):
    """Get file size in MB"""
    try:
        return os.path.getsize(file_path) / (1024 * 1024)
    except:
        return 0


def cleanup_old_backups():
    """Clean up backup files older than retention period"""
    try:
        users_dir = os.path.join(SCHEDULES_DATA_DIR, "users")
        if not os.path.exists(users_dir):
            return

        cutoff_time = datetime.now() - timedelta(days=BACKUP_RETENTION_DAYS)
        cleaned_count = 0

        for user_folder in os.listdir(users_dir):
            user_path = os.path.join(users_dir, user_folder)
            if not os.path.isdir(user_path):
                continue

            for filename in os.listdir(user_path):
                file_path = os.path.join(user_path, filename)

                # Skip latest files and settings
                if filename in ["schedules_latest.json", "app_settings.json"]:
                    continue

                # Check if file is backup file (schedules_*.json.gz)
                if filename.startswith('schedules_') and filename.endswith('.json.gz'):
                    if os.path.isfile(file_path):
                        file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                        if file_time < cutoff_time:
                            file_size = get_file_size_mb(file_path)
                            os.remove(file_path)
                            cleaned_count += 1
                            print(f"Cleaned up: {filename} ({file_size:.2f}MB)")

        return cleaned_count
    except Exception as e:
        print(f"Cleanup error: {e}")
        return 0


# --- API Endpoints ---

@router.get("/api/backup-database")
async def backup_database(user_id: str = Query(...)):
    """ì‚¬ìš©ìë³„ ë°ì´í„°ë¥¼ JSON í˜•íƒœë¡œ ì•ˆì „í•˜ê²Œ ë°±ì—…"""
    db = None
    try:
        logger.info(f"ğŸ”„ Starting backup for user: {user_id}")

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        db = SessionLocal()
        logger.info("âœ… Database connection established")

        service = ScheduleService(db)
        logger.info("âœ… ScheduleService initialized")

        # Google ì‚¬ìš©ì IDì— ì ‘ë‘ì‚¬ ì¶”ê°€
        original_user_id = user_id
        if not user_id.startswith('google_') and user_id != 'anonymous':
            user_id = f'google_{user_id}'

        logger.info(f"ğŸ”„ Processed user ID: {original_user_id} -> {user_id}")

        # í•´ë‹¹ ì‚¬ìš©ìì˜ ëª¨ë“  ìŠ¤ì¼€ì¤„ ê°€ì ¸ì˜¤ê¸°
        logger.info(f"ğŸ”„ Fetching schedules for user: {user_id}")
        schedules = service.get_all_schedules(user_id)
        logger.info(f"âœ… Found {len(schedules) if schedules else 0} schedules")

        if not schedules:
            logger.warning(f"âš ï¸  No schedules found for user: {user_id}")
            return {
                "success": False,
                "message": "ë°±ì—…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            }

        # JSON í˜•íƒœë¡œ ë³€í™˜ (ID ì œì™¸, ì‚¬ìš©ìë³„ ë°ì´í„°ë§Œ)
        logger.info("ğŸ”„ Converting schedules to dict format")

        # schedulesë¥¼ ì•ˆì „í•˜ê²Œ dictë¡œ ë³€í™˜
        schedule_dicts = []
        for i, schedule in enumerate(schedules):
            try:
                schedule_dict = schedule.to_dict()
                schedule_dicts.append(schedule_dict)
                logger.debug(f"âœ… Converted schedule {i+1}/{len(schedules)}")
            except Exception as e:
                logger.error(f"âŒ Failed to convert schedule {i+1}: {str(e)}")
                # ë³€í™˜ ì‹¤íŒ¨í•œ ìŠ¤ì¼€ì¤„ì€ ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
                continue

        backup_data = {
            "version": "v2025.01",
            "backup_date": datetime.now().isoformat(),
            "user_id": user_id,
            "schedules": schedule_dicts
        }

        logger.info(f"âœ… Backup data prepared with {len(schedule_dicts)} schedules")

        return {
            "success": True,
            "backup_data": backup_data,
            "count": len(schedule_dicts),
            "message": f"{len(schedule_dicts)}ê°œì˜ ìŠ¤ì¼€ì¤„ì´ ë°±ì—…ë˜ì—ˆìŠµë‹ˆë‹¤."
        }

    except Exception as e:
        error_msg = f"ë°±ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        logger.error(f"âŒ Backup failed: {str(e)}")
        logger.error(f"âŒ Error type: {type(e).__name__}")
        import traceback
        logger.error(f"âŒ Traceback: {traceback.format_exc()}")

        return {
            "success": False,
            "message": error_msg
        }
    finally:
        if db:
            try:
                db.close()
                logger.info("âœ… Database connection closed")
            except Exception as e:
                logger.error(f"âŒ Error closing database: {str(e)}")


@router.post("/api/restore-database")
async def restore_database(request: dict = Body(...)):
    """ì‚¬ìš©ìë³„ JSON ë°±ì—… ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë³µì›"""
    try:
        db = SessionLocal()
        service = ScheduleService(db)

        user_id = request.get('user_id')
        backup_data = request.get('backup_data')

        # Google ì‚¬ìš©ì IDì— ì ‘ë‘ì‚¬ ì¶”ê°€
        if user_id and not user_id.startswith('google_') and user_id != 'anonymous':
            user_id = f'google_{user_id}'

        if not user_id or not backup_data:
            return {
                "success": False,
                "message": "ì‚¬ìš©ì IDì™€ ë°±ì—… ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }

        # ë°±ì—… ë°ì´í„° ê²€ì¦
        if not isinstance(backup_data, dict) or 'schedules' not in backup_data:
            return {
                "success": False,
                "message": "ìœ íš¨í•˜ì§€ ì•Šì€ ë°±ì—… ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤."
            }

        schedules_data = backup_data['schedules']
        if not isinstance(schedules_data, list):
            return {
                "success": False,
                "message": "ìŠ¤ì¼€ì¤„ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
            }

        # í•´ë‹¹ ì‚¬ìš©ìì˜ ê¸°ì¡´ ë°ì´í„° ëª¨ë‘ ì‚­ì œ
        existing_count = service.get_schedule_count(user_id)
        if existing_count > 0:
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            db.query(Schedule).filter(Schedule.user_id == user_id).delete()
            db.commit()

        # ìƒˆë¡œìš´ ë°ì´í„° ë²Œí¬ ì¶”ê°€ (ì„±ëŠ¥ ìµœì í™”)
        added_count = 0
        schedules_to_insert = []

        for schedule_data in schedules_data:
            try:
                # ID í•„ë“œ ì œê±° (ìƒˆë¡œ ìƒì„±ë˜ë„ë¡)
                if 'id' in schedule_data:
                    del schedule_data['id']

                # ìŠ¤ì¼€ì¤„ ê°ì²´ ìƒì„± (ì•„ì§ DBì— ì‚½ì…í•˜ì§€ ì•ŠìŒ)
                schedule = Schedule.from_dict(schedule_data, user_id)
                schedules_to_insert.append(schedule)
                added_count += 1
            except Exception as e:
                print(f"ìŠ¤ì¼€ì¤„ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
                continue

        # ë²Œí¬ ì‚½ì… (í•œ ë²ˆì— ëª¨ë“  ë°ì´í„° ì‚½ì…)
        if schedules_to_insert:
            db.add_all(schedules_to_insert)
            db.commit()

        return {
            "success": True,
            "message": f"ë³µì› ì™„ë£Œ: {existing_count}ê°œ ì‚­ì œ, {added_count}ê°œ ì¶”ê°€",
            "deleted_count": existing_count,
            "added_count": added_count
        }

    except Exception as e:
        return {
            "success": False,
            "message": f"ë³µì› ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }
    finally:
        db.close()


@router.post("/api/cleanup-backups")
def manual_cleanup():
    """Manually trigger backup cleanup"""
    try:
        cleaned_count = cleanup_old_backups()
        return {
            "success": True,
            "message": f"Cleaned up {cleaned_count} old backup files",
            "cleaned_count": cleaned_count
        }
    except Exception as e:
        return {"error": f"Cleanup failed: {str(e)}", "success": False}
