import re
from dataclasses import dataclass, field
from typing import List, Dict, Tuple, Optional, Any
from datetime import datetime, timedelta

# NLP imports (spaCy)
try:
    import spacy
    nlp = spacy.load('ko_core_news_sm')
    NLP_AVAILABLE = True
except (ImportError, OSError):
    nlp = None
    NLP_AVAILABLE = False

# --- Constants ---
BRAND_PATTERNS = [
    r'K\s*\[\s*ì„¸ë¸ìŠ¤\s*\]',  # K [ ì„¸ë¸ìŠ¤ ]
    r'K\s*ì„¸ë¸ìŠ¤',             # K ì„¸ë¸ìŠ¤
    r'B\s*ì„¸ë¸ìŠ¤',             # B ì„¸ë¸ìŠ¤
    r'A\s*ì„¸ë¸ìŠ¤í”„ë¦¬ë¯¸ì—„',      # A ì„¸ë¸ìŠ¤í”„ë¦¬ë¯¸ì—„
    r'ë”ê·¸ë¼í”¼',               # ë”ê·¸ë¼í”¼
    r'ì„¸ì»¨í”Œë¡œìš°'              # ì„¸ì»¨í”Œë¡œìš°
]

ALBUM_PATTERNS = [
    r'ê¸°ë³¸\s*\d{2,3}[Pp]',    # ê¸°ë³¸30P, ê¸°ë³¸ 30P, ê¸°ë³¸50p ë“± (ê³µë°± í—ˆìš©)
    r'\d{2,3}[Pp]',           # 30P, 40P, 30p, 40p ë“± (ëŒ€ì†Œë¬¸ì ëª¨ë‘)
]

PHOTOGRAPHER_EXCLUDED_TERMS = [
    'íë°±ì—†ìŒ', 'íë°±ìˆìŒ', 'íë°±ì§„í–‰', 'íë°±ì œì™¸', 'íë°±ë¯¸ì •', 'íë°±ìƒëµ',
    'ì„ ì´¬ì˜', 'í™€ìŠ¤ëƒ…', 'ì£¼ë¡€ì—†ìŒ', 'ì£¼ë¡€ìˆìŒ', 'í”Œë˜ì‹œì»·', 'í”Œë¼ì›Œìƒ¤ì›Œ'
]

PHOTOGRAPHER_NAMES = [
    'ì•ˆí˜„ìš°', 'í™ê¸¸ë™', 'ê¹€ì˜ìˆ˜', 'ì´ë¯¼í˜¸', 'ë°•ì§€ì„±', 'ìµœì˜í¬', 'ì •ìˆ˜ì—°', 'ë‚˜ì€ë¹ˆ'
]

DEFAULT_ALBUM = '30P'
MANAGER_NAME = 'KPAG(ì—…ë¬´ìš©)'

# NLP-style parsing constants
LOCATION_KEYWORDS = [
    'í˜¸í…”', 'ì›¨ë”©í™€', 'ì»¨ë²¤ì…˜', 'êµíšŒ', 'ì„±ë‹¹', 'ì±„í”Œ', 'ìŠ¤íŠœë””ì˜¤', 'í™€', 'ì„¼í„°', 'íƒ€ì›Œ',
    'ê·¸ëœë“œ', 'ë©”ë¥´ì‹œì•™', 'í”Œë¡œíŒ…', 'ì´ë¦¬ìŠ¤', 'í•˜ìš°ìŠ¤', 'íŒ°ë¦¬ìŠ¤', 'ë ˆì§€ë˜ìŠ¤'
]

COMMON_WORDS = [
    'ìŠ¤ì¼€ì¤„', 'ì´¬ì˜', 'ì—°ë½', 'ë“œë ¤', 'ë´…ë‹ˆë‹¤', 'ì£¼ì„¸ìš”', 'ê°€ëŠ¥', 'ìˆìœ¼ë©´', 'í•´ì„œ',
    'ê±´ë‹¹', 'ë§Œì›', 'ì¶”ê°€', 'ì…ë‹ˆë‹¤', 'ì¶œì¥ë¹„', 'ì˜ˆì•½', 'ë¬¸ì˜', 'í™•ì¸'
]

# Date prediction constants
WEEKDAY_PATTERNS = {
    r'ì¼ìš”ì¼?': 6,  # Sunday
    r'ì›”ìš”ì¼?': 0,  # Monday
    r'í™”ìš”ì¼?': 1,  # Tuesday
    r'ìˆ˜ìš”ì¼?': 2,  # Wednesday
    r'ëª©ìš”ì¼?': 3,  # Thursday
    r'ê¸ˆìš”ì¼?': 4,  # Friday
    r'í† ìš”ì¼?': 5   # Saturday
}

# Date prediction functions
def get_next_saturday():
    """ì´ë²ˆ ì£¼ í† ìš”ì¼ ë‚ ì§œë¥¼ ë°˜í™˜"""
    today = datetime.now()
    days_ahead = 5 - today.weekday()  # Saturday is 5 (Monday=0)
    if days_ahead <= 0:  # ì´ë¯¸ ì§€ë‚¬ìœ¼ë©´ ë‹¤ìŒ ì£¼ í† ìš”ì¼
        days_ahead += 7
    saturday = today + timedelta(days=days_ahead)
    return saturday.strftime("%mì›” %dì¼")

def get_date_from_weekday(weekday_text):
    """ìš”ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ í•´ë‹¹ ìš”ì¼ì˜ ë‚ ì§œë¥¼ ë°˜í™˜"""
    today = datetime.now()

    # ìš”ì¼ íŒ¨í„´ ë§¤ì¹­
    target_weekday = None
    for pattern, weekday_num in WEEKDAY_PATTERNS.items():
        if re.search(pattern, weekday_text):
            target_weekday = weekday_num
            break

    if target_weekday is None:
        return get_next_saturday()  # ê¸°ë³¸ê°’ì€ ì´ë²ˆ ì£¼ í† ìš”ì¼

    # ê°€ì¥ ê°€ê¹Œìš´ í•´ë‹¹ ìš”ì¼ ì°¾ê¸°
    days_ahead = target_weekday - today.weekday()
    if days_ahead <= 0:  # ì´ë¯¸ ì§€ë‚¬ìœ¼ë©´ ë‹¤ìŒ ì£¼
        days_ahead += 7

    target_date = today + timedelta(days=days_ahead)
    return target_date.strftime("%mì›” %dì¼")

def predict_date_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¶”ì¸¡í•´ì„œ ë°˜í™˜"""
    # ê¸°ì¡´ ë‚ ì§œ íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸
    date_patterns = [
        r'(\d{1,2})ì›”\s*(\d{1,2})ì¼',  # MMì›” DDì¼
        r'(\d{4})[-./](\d{1,2})[-./](\d{1,2})',  # YYYY-MM-DD
        r'(\d{1,2})[-./](\d{1,2})',  # MM-DD
    ]

    for pattern in date_patterns:
        if re.search(pattern, text):
            return None  # ê¸°ì¡´ ë‚ ì§œê°€ ìˆìœ¼ë©´ None ë°˜í™˜ (ë³€ê²½ ì—†ìŒ)

    # ìš”ì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    for pattern in WEEKDAY_PATTERNS.keys():
        if re.search(pattern, text):
            return get_date_from_weekday(text)

    # ë‚ ì§œ ì •ë³´ê°€ ì „í˜€ ì—†ìœ¼ë©´ ì´ë²ˆ ì£¼ í† ìš”ì¼
    return get_next_saturday()

# Legacy constants (deprecated - use above constants instead)
BRANDS_WITH_CONTACT_NEXT = ['A ì„¸ë¸ìŠ¤í”„ë¦¬ë¯¸ì—„', 'ë”ê·¸ë¼í”¼', 'ì„¸ì»¨í”Œë¡œìš°']
BRAND_WITH_DUMMY_DATA = 'ì„¸ì»¨í”Œë¡œìš°'

@dataclass
class Schedule:
    # Core fields
    date: str = ""
    location: str = ""
    time: str = ""
    couple: str = ""
    # Parsed fields
    contact: str = ""
    brand: str = ""
    album: str = ""
    photographer: str = ""
    memo: str = ""
    manager: str = ""
    price: int = 0  # ì´¬ì˜ë‹¨ê°€ (ìˆ«ìë§Œ)
    needs_review: bool = False
    review_reason: str = ""  # ê²€í†  í•„ìš” ì´ìœ 

    def to_dict(self) -> Dict:
        return self.__dict__

# --- Helper Functions ---
def extract_date(line: str) -> str:
    """
    Extract the date pattern (YYYY.MM.DD) from a line.
    Returns the clean date string or empty string if not found.
    This is more flexible and handles various formatting issues.
    """
    # Look for YYYY.MM.DD pattern anywhere in the line
    # More flexible pattern that doesn't require word boundaries
    date_pattern = r'(\d{4}\.\d{2}\.\d{2})'
    match = re.search(date_pattern, line.strip())
    return match.group(1) if match else ""

def is_valid_date(line: str) -> bool:
    """
    Check if line contains a valid date pattern (YYYY.MM.DD).
    This approach searches for the date pattern anywhere in the line,
    making it resilient to various formatting issues and typos.
    """
    return bool(extract_date(line))
def is_valid_time(line: str) -> bool: return bool(re.match(r'^\d{2}:\d{2}$', line.strip()))
def is_valid_couple(line: str) -> bool:
    line = line.strip()

    # ìˆ«ìê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì‹ ë‘ì‹ ë¶€ê°€ ì•„ë‹˜
    if any(char.isdigit() for char in line):
        return False

    # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ê²½ìš°
    parts = line.split()

    # í•œ ëª…ì˜ ì´ë¦„ (ì‹ ë‘ ë˜ëŠ” ì‹ ë¶€ë§Œ)
    if len(parts) == 1 and 2 <= len(parts[0]) <= 10 and all(c.isalpha() and '\uac00' <= c <= '\ud7af' for c in parts[0]):
        return True

    # ì¼ë°˜ì ì¸ 2ê°œ ì´ë¦„ (ê¸°ì¡´ ë°©ì‹)
    if len(parts) == 2 and all(len(p) <= 10 for p in parts):
        return True

    # ì™¸ì ì´ë¦„ íŒ¨í„´ (3ê°œ ë¶€ë¶„)
    if len(parts) == 3 and re.match(r'^[ê°€-í£]+\s+[ê°€-í£]+\s+[ê°€-í£]+$', line):
        # íŒ¨í„´ 1: "ë°°ìŠ¹í¬ ìœ¤ ì •" (í•œê¸€ì´ë¦„ + í•œê¸€ì + í•œê¸€ì)
        if len(parts[1]) == 1 and len(parts[2]) == 1:
            return True
        # íŒ¨í„´ 2: "ì´ ì¤€ ì´ì£¼ì—°" (í•œê¸€ì + í•œê¸€ì + í•œê¸€ì´ë¦„)
        if len(parts[0]) == 1 and len(parts[1]) == 1:
            return True

    # ê³µë°± ì—†ì´ ë¶™ì–´ìˆëŠ” ê²½ìš°: 4ê¸€ì ì´ìƒì˜ í•œê¸€ë§Œ í—ˆìš© (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    if len(parts) == 1 and len(line) >= 4 and all(c.isalpha() and '\uac00' <= c <= '\ud7af' for c in line):
        return True

    return False

def separate_couple_names(couple_str: str) -> str:
    """
    ë¶™ì–´ìˆëŠ” ì‹ ë‘ì‹ ë¶€ ì´ë¦„ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    ì˜ˆ: 'ì˜¤ì„¸ì¤€ì´ì§€ì„ ' -> 'ì˜¤ì„¸ì¤€ ì´ì§€ì„ '
    ì˜ˆ: 'ë°°ìŠ¹í¬ ìœ¤ ì •' -> 'ë°°ìŠ¹í¬ ìœ¤ì •' (ë’¤ìª½ ì™¸ì ì´ë¦„ ì •ë¦¬)
    ì˜ˆ: 'ì´ ì¤€ ì´ì£¼ì—°' -> 'ì´ì¤€ ì´ì£¼ì—°' (ì•ìª½ ì™¸ì ì´ë¦„ ì •ë¦¬)
    """
    couple_str = couple_str.strip()

    # ì™¸ì ì´ë¦„ íŒ¨í„´ ì²˜ë¦¬
    if re.match(r'^[ê°€-í£]+\s+[ê°€-í£]+\s+[ê°€-í£]+$', couple_str):
        parts = couple_str.split()
        if len(parts) == 3:
            # íŒ¨í„´ 1: "ë°°ìŠ¹í¬ ìœ¤ ì •" -> "ë°°ìŠ¹í¬ ìœ¤ì •"
            if len(parts[1]) == 1 and len(parts[2]) == 1:
                return f"{parts[0]} {parts[1]}{parts[2]}"
            # íŒ¨í„´ 2: "ì´ ì¤€ ì´ì£¼ì—°" -> "ì´ì¤€ ì´ì£¼ì—°"
            elif len(parts[0]) == 1 and len(parts[1]) == 1:
                return f"{parts[0]}{parts[1]} {parts[2]}"

    # ì´ë¯¸ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë‹¨, ì™¸ì íŒ¨í„´ ì œì™¸)
    if ' ' in couple_str:
        return couple_str

    # 4ê¸€ì ì´ìƒì¸ í•œê¸€ ë¬¸ìì—´ë§Œ ì²˜ë¦¬
    if len(couple_str) < 4 or not all(c.isalpha() and '\uac00' <= c <= '\ud7af' for c in couple_str):
        return couple_str

    # 6ê¸€ìë©´ 3ê¸€ìì”© ë¶„ë¦¬ (ê°€ì¥ ì¼ë°˜ì ì¸ í•œêµ­ì¸ ì´ë¦„ íŒ¨í„´)
    if len(couple_str) == 6:
        return f"{couple_str[:3]} {couple_str[3:]}"

    # ê°€ëŠ¥í•œ ë¶„ë¦¬ ìœ„ì¹˜ë“¤ì„ ì‹œë„ (3ê¸€ì ìš°ì„ , ê·¸ ë‹¤ìŒ 2ê¸€ì)
    possible_splits = []

    # 3ê¸€ì + ë‚˜ë¨¸ì§€ (ìš°ì„ ìˆœìœ„)
    if len(couple_str) >= 5:
        possible_splits.append((couple_str[:3], couple_str[3:]))

    # 2ê¸€ì + ë‚˜ë¨¸ì§€ (ì°¨ì„ ì±…)
    if len(couple_str) >= 4:
        possible_splits.append((couple_str[:2], couple_str[2:]))

    # ì´ë¦„ìœ¼ë¡œ ì ì ˆí•œ ë¶„ë¦¬ë¥¼ ì°¾ê¸° (2-4ê¸€ì ë²”ìœ„)
    for first, second in possible_splits:
        if 2 <= len(first) <= 4 and 2 <= len(second) <= 4:
            return f"{first} {second}"

    # ë¶„ë¦¬í•  ìˆ˜ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    return couple_str

def is_valid_photographer_name(name: str) -> bool:
    name = name.strip()
    if name in PHOTOGRAPHER_EXCLUDED_TERMS:
        return False
    return bool(re.match(r'^[ê°€-í£]{2,4}$', name))
def parse_contact(line: str) -> str:
    m = re.search(r'(010[- .]?\d{4}[- .]?\d{4})', line)
    if not m:
        return ""

    # Extract only digits and format as 010-XXXX-XXXX
    digits = re.sub(r'[^0-9]', '', m.group(1))
    if len(digits) == 11 and digits.startswith('010'):
        return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
    return m.group(1)  # Return original if formatting fails
def clean_location(location: str) -> str:
    """Clean location name by removing parentheses content, 'ë‹¨ë…'/'ë‹¨ë…í™€', trailing 'í™€', and standardizing names"""
    if not location:
        return location

    # Remove parentheses and their content (e.g., "(17ì¸µ)", "(í•´ìš´ëŒ€)")
    location = re.sub(r'\([^)]*\)', '', location).strip()

    # Remove "ë‹¨ë…" or "ë‹¨ë…í™€"
    location = re.sub(r'ë‹¨ë…í™€?', '', location).strip()

    # Remove "í™€" at the end of location name
    if location.endswith('í™€'):
        location = location[:-1].strip()

    # Standardize specific location names
    venue_replacements = {
        'ë”ë¸”ìœ ': 'ì„¼í…€',
        'ê·¸ëœë“œ ë¸”ë‘': 'ê·¸ëœë“œë¸”ë‘'
    }

    for old_name, new_name in venue_replacements.items():
        if old_name in location:
            location = location.replace(old_name, new_name)

    return location.strip()
def parse_brand_album(line: str) -> (str, str):
    # Create regex pattern from BRAND_PATTERNS
    brand_pattern = '|'.join([f'({pattern})' for pattern in BRAND_PATTERNS])
    brand_match = re.search(brand_pattern, line)

    # Create regex pattern from ALBUM_PATTERNS
    album_pattern = '|'.join([f'({pattern})' for pattern in ALBUM_PATTERNS])
    album_match = re.search(album_pattern, line, re.IGNORECASE)

    # ë¸Œëœë“œ: ëŒ€ê´„í˜¸ ì œê±°, trim, ì—°ì† ê³µë°± ì •ê·œí™”
    brand = brand_match.group(0).replace('[', '').replace(']', '').strip() if brand_match else ""
    if brand:
        brand = re.sub(r'\s+', ' ', brand)  # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ

    # ì•¨ë²”: ëŒ€ë¬¸ì ë³€í™˜, ì—°ì† ê³µë°± ì •ê·œí™”
    album = album_match.group(0).upper() if album_match else ""
    if album:
        album = re.sub(r'\s+', ' ', album)  # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ

    # "ê¸°ë³¸ 30P" í˜•íƒœì—ì„œ ê³µë°± ì œê±°í•˜ì—¬ "ê¸°ë³¸30P"ë¡œ ì •ê·œí™”
    if album and 'ê¸°ë³¸' in album:
        album = re.sub(r'ê¸°ë³¸\s*(\d{2,3}[Pp])', r'ê¸°ë³¸\1', album, flags=re.IGNORECASE)

    # If no album found but "ê¸°ë³¸" is mentioned, default to DEFAULT_ALBUM
    if not album and "ê¸°ë³¸" in line:
        album = DEFAULT_ALBUM

    # If brand exists but no album and line only contains brand (and whitespace), default to DEFAULT_ALBUM
    if brand and not album:
        # Remove the brand from line and check if remaining text is minimal
        remaining_text = line
        if brand_match:
            remaining_text = line.replace(brand_match.group(0), '').strip()

        # If remaining text is empty or only contains brackets/spaces, default to DEFAULT_ALBUM
        if not remaining_text or re.match(r'^[\[\]\s]*$', remaining_text):
            album = DEFAULT_ALBUM

    return brand, album

def detect_chat_format(raw_text: str) -> str:
    """
    Detect if the chat log is from desktop, mobile, or compact format.
    Returns 'desktop', 'mobile', 'compact', or 'unknown'.
    """
    lines = raw_text.splitlines()[:50]  # Check first 50 lines for format detection

    desktop_pattern_count = 0
    mobile_pattern_count = 0
    compact_pattern_count = 0

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # Desktop format: [Speaker] [ì˜¤ì „/ì˜¤í›„ HH:MM] content
        if re.search(r'^\[([^\]]+)\]\s*\[(ì˜¤ì „|ì˜¤í›„)\s*\d{1,2}:\d{2}\]', line):
            desktop_pattern_count += 1

        # Mobile format: YYYYë…„ MMì›” DDì¼ ì˜¤ì „/ì˜¤í›„ HH:MM, Speaker : content
        elif re.search(r'^\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼\s*(ì˜¤ì „|ì˜¤í›„)\s*\d{1,2}:\d{2},\s*[^:]+\s*:', line):
            mobile_pattern_count += 1

        # Compact format patterns:
        # 1. MMì›” DDì¼ HHì‹œ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€
        # 2. MMì›” DDì¼ HHì‹œMMë¶„ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€
        # 3. MMì›” DDì¼ HH:MMì‹œ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€
        # 4. ì¥ì†Œ HHì‹œ (incomplete format)
        # 5. ì¥ì†Œëª… HHì‹œMMë¶„ (more incomplete)
        elif (re.search(r'^\d{1,2}ì›”\s*\d{1,2}ì¼\s*\d{1,2}ì‹œ(?:\d{1,2}ë¶„|:\d{2}ì‹œ)?\s+.+\s+[ê°€-í£]+\s+[ê°€-í£]+\s*-\s*[ê°€-í£]+\s*ì‘ê°€', line) or
              re.search(r'^[ê°€-í£\s"]+\s+\d{1,2}ì‹œ(?:\d{1,2}ë¶„)?(?:\s+[ê°€-í£\s]*)?$', line) or
              re.search(r'^\d{1,2}ì›”\d{1,2}ì¼\s+[ê°€-í£]+', line)):
            compact_pattern_count += 1

    if compact_pattern_count > 0:
        return 'compact'
    elif desktop_pattern_count > mobile_pattern_count:
        return 'desktop'
    elif mobile_pattern_count > 0:
        return 'mobile'
    else:
        return 'unknown'

def split_chat_by_speaker_desktop(raw_text: str) -> List[Tuple[str, str]]:
    """Splits the desktop format chat log into blocks per speaker turn."""
    speaker_blocks = []
    current_speaker = ""
    current_block = []
    # Desktop format: [Speaker] [ì˜¤ì „/ì˜¤í›„ HH:MM] content
    speaker_line_re = re.compile(r'^\[([^\]]+)\]\s*\[(ì˜¤ì „|ì˜¤í›„)\s*\d{1,2}:\d{2}\]')

    for line in raw_text.splitlines():
        match = speaker_line_re.match(line)
        if match:
            # If a new speaker starts, save the previous block
            if current_speaker and current_block:
                speaker_blocks.append((current_speaker, "\n".join(current_block)))

            # Start a new block
            current_speaker = match.group(1)
            # The actual content of the line is after the matched tag
            content_line = line[match.end():].strip()
            current_block = [content_line] if content_line else []
        elif current_speaker: # This is a multi-line message
            current_block.append(line.strip())

    # Add the last block
    if current_speaker and current_block:
        speaker_blocks.append((current_speaker, "\n".join(current_block)))

    return speaker_blocks

def split_chat_by_speaker_mobile(raw_text: str) -> List[Tuple[str, str]]:
    """Splits the mobile format chat log into blocks per speaker turn."""
    speaker_blocks = []
    current_speaker = ""
    current_block = []

    # Mobile format: YYYYë…„ MMì›” DDì¼ ì˜¤ì „/ì˜¤í›„ HH:MM, Speaker : content
    speaker_line_re = re.compile(r'^\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼\s*(ì˜¤ì „|ì˜¤í›„)\s*\d{1,2}:\d{2},\s*([^:]+)\s*:\s*(.*)')

    for line in raw_text.splitlines():
        line = line.strip()
        if not line:
            continue

        match = speaker_line_re.match(line)
        if match:
            # If a new speaker starts, save the previous block
            if current_speaker and current_block:
                speaker_blocks.append((current_speaker, "\n".join(current_block)))

            # Start a new block
            current_speaker = match.group(2).strip()
            content_line = match.group(3).strip()
            current_block = [content_line] if content_line else []
        elif current_speaker: # This is a multi-line message
            current_block.append(line)

    # Add the last block
    if current_speaker and current_block:
        speaker_blocks.append((current_speaker, "\n".join(current_block)))

    return speaker_blocks

def parse_compact_format(raw_text: str) -> List[Schedule]:
    """
    Parse compact format messages like:
    10ì›”
    10ì›” 25ì¼ 13ì‹œ í•˜ìš°ìŠ¤ ì²œì¥ê·¼ ì´í˜„ì£¼ - ë°•ë³‘ì°¬ ì‘ê°€
    10ì›” 26ì¼ 11ì‹œ ì´ë¦¬ìŠ¤ ì‹ ìƒëª© ìµœí¬ì¬ - ë°•ë³‘ì°¬ ì‘ê°€
    11ì›” 15ì¼ 13ì‹œ30ë¶„ ì´ë¦¬ìŠ¤ ì»¨ë²¤ì…˜ ê¹€ì§€í™˜ ê¹€ë¯¼ì • - ë°•ë³‘ì°¬ ì‘ê°€
    11ì›” 22ì¼ 13:30ì‹œ ì´ë¦¬ìŠ¤ ì„œì„±ì¤€ ë°°ì§€ì› - ë°•ë³‘ì°¬ ì‘ê°€
    í•´ìš´ëŒ€ ê·¸ëœë“œì¡°ì„ í˜¸í…” 12ì‹œ
    """
    schedules = []
    lines = [line.strip() for line in raw_text.splitlines() if line.strip()]

    current_month = None
    current_year = datetime.now().year  # ê¸°ë³¸ì ìœ¼ë¡œ í˜„ì¬ ì—°ë„ ì‚¬ìš©

    for line in lines:
        # ì›” í—¤ë” ê°ì§€ (ì˜ˆ: "10ì›”")
        month_match = re.match(r'^(\d{1,2})ì›”$', line)
        if month_match:
            current_month = int(month_match.group(1))
            continue

        # íŒ¨í„´ 1: MMì›” DDì¼ HHì‹œMMë¶„ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€ (ë¶„ ë‹¨ìœ„ í¬í•¨)
        schedule_match = re.match(
            r'^(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2})ì‹œ(\d{1,2})ë¶„\s+(.+?)\s+([ê°€-í£]+)\s+([ê°€-í£]+)\s*-\s*([ê°€-í£]+)\s*ì‘ê°€',
            line
        )
        if schedule_match:
            month = int(schedule_match.group(1))
            day = int(schedule_match.group(2))
            hour = int(schedule_match.group(3))
            minute = int(schedule_match.group(4))
            location = schedule_match.group(5).strip()
            groom = schedule_match.group(6).strip()
            bride = schedule_match.group(7).strip()
            photographer = schedule_match.group(8).strip()

            if current_month is None:
                current_month = month

            date = f"{current_year}.{month:02d}.{day:02d}"
            time = f"{hour:02d}:{minute:02d}"
            couple = f"{groom} {bride}"

            schedule = Schedule(
                date=date, location=clean_location(location), time=time, couple=couple,
                photographer=photographer, manager="", brand="", album="",
                contact="", memo="", needs_review=True,
                review_reason="ê°„ê²°í•œ í˜•ì‹: ë¸Œëœë“œ, ì•¨ë²”, ê³„ì•½ì ì •ë³´ ëˆ„ë½"
            )
            schedules.append(schedule)
            continue

        # íŒ¨í„´ 2: MMì›” DDì¼ HH:MMì‹œ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€ (ì½œë¡  í˜•íƒœ)
        schedule_match = re.match(
            r'^(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2}):(\d{2})ì‹œ\s+(.+?)\s+([ê°€-í£]+)\s+([ê°€-í£]+)\s*-\s*([ê°€-í£]+)\s*ì‘ê°€',
            line
        )
        if schedule_match:
            month = int(schedule_match.group(1))
            day = int(schedule_match.group(2))
            hour = int(schedule_match.group(3))
            minute = int(schedule_match.group(4))
            location = schedule_match.group(5).strip()
            groom = schedule_match.group(6).strip()
            bride = schedule_match.group(7).strip()
            photographer = schedule_match.group(8).strip()

            if current_month is None:
                current_month = month

            date = f"{current_year}.{month:02d}.{day:02d}"
            time = f"{hour:02d}:{minute:02d}"
            couple = f"{groom} {bride}"

            schedule = Schedule(
                date=date, location=clean_location(location), time=time, couple=couple,
                photographer=photographer, manager="", brand="", album="",
                contact="", memo="", needs_review=True,
                review_reason="ê°„ê²°í•œ í˜•ì‹: ë¸Œëœë“œ, ì•¨ë²”, ê³„ì•½ì ì •ë³´ ëˆ„ë½"
            )
            schedules.append(schedule)
            continue

        # íŒ¨í„´ 3: MMì›” DDì¼ HHì‹œ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€ (ê¸°ë³¸ í˜•íƒœ)
        schedule_match = re.match(
            r'^(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2})ì‹œ\s+(.+?)\s+([ê°€-í£]+)\s+([ê°€-í£]+)\s*-\s*([ê°€-í£]+)\s*ì‘ê°€',
            line
        )
        if schedule_match:
            month = int(schedule_match.group(1))
            day = int(schedule_match.group(2))
            hour = int(schedule_match.group(3))
            location = schedule_match.group(4).strip()
            groom = schedule_match.group(5).strip()
            bride = schedule_match.group(6).strip()
            photographer = schedule_match.group(7).strip()

            if current_month is None:
                current_month = month

            date = f"{current_year}.{month:02d}.{day:02d}"
            time = f"{hour:02d}:00"
            couple = f"{groom} {bride}"

            schedule = Schedule(
                date=date, location=clean_location(location), time=time, couple=couple,
                photographer=photographer, manager="", brand="", album="",
                contact="", memo="", needs_review=True,
                review_reason="ê°„ê²°í•œ í˜•ì‹: ë¸Œëœë“œ, ì•¨ë²”, ê³„ì•½ì ì •ë³´ ëˆ„ë½"
            )
            schedules.append(schedule)
            continue

        # ğŸ¤– NLP ê¸°ë°˜ ìœ ì—°í•œ íŒŒì„œ (íŒ¨í„´ 4-7 ë° FALLBACK ëŒ€ì²´)
        try:
            extracted_schedule = nlp_parse_flexible_format(line, current_year)
            if extracted_schedule:
                schedules.append(extracted_schedule)
        except Exception as e:
            pass

    return schedules

def extract_korean_words(text: str) -> List[str]:
    """í•œê¸€ ë‹¨ì–´ë§Œ ì¶”ì¶œ (ê°„ë‹¨í•œ í† í°í™”)"""
    words = re.findall(r'[ê°€-í£]{2,4}', text)
    return [word for word in words if word not in COMMON_WORDS]

def extract_location_smart(text: str) -> str:
    """ìŠ¤ë§ˆíŠ¸ ì¥ì†Œ ì¶”ì¶œ"""
    words = text.split()
    venue_parts = []

    for word in words:
        clean_word = word.replace('"', '').replace("'", '')

        if any(keyword in clean_word for keyword in LOCATION_KEYWORDS):
            venue_parts.append(clean_word)
        elif re.match(r'^[ê°€-í£]{3,}$', clean_word) and clean_word not in COMMON_WORDS:
            venue_parts.append(clean_word)

    return ' '.join(location_parts[:2])

def extract_names_smart(text: str) -> List[str]:
    """ìŠ¤ë§ˆíŠ¸ ì´ë¦„ ì¶”ì¶œ"""
    words = extract_korean_words(text)
    names = []

    for word in words:
        if 2 <= len(word) <= 4:
            if not any(keyword in word for keyword in LOCATION_KEYWORDS):
                if word not in ['ì»¨ë²¤ì…˜', 'ì›¨ë”©í™€', 'ìŠ¤ëª°ì›¨ë”©']:
                    names.append(word)

    return list(set(names))

def extract_schedule_with_nlp(text: str) -> Dict[str, Any]:
    """ê°€ë²¼ìš´ NLP ìŠ¤íƒ€ì¼ ìŠ¤ì¼€ì¤„ ì •ë³´ ì¶”ì¶œ"""
    components = {
        'date': '', 'time': '', 'location': '', 'names': [], 'photographer': '', 'weekday': ''
    }

    # ì‹œê°„ ì¶”ì¶œ
    time_patterns = [r'(\d{1,2})ì‹œ(\d{1,2})ë¶„', r'(\d{1,2}):(\d{2})', r'(\d{1,2})ì‹œ']
    for pattern in time_patterns:
        match = re.search(pattern, text)
        if match:
            if len(match.groups()) == 2:
                hour, minute = match.groups()
                components['time'] = f"{int(hour):02d}:{int(minute):02d}"
            else:
                hour = match.group(1)
                components['time'] = f"{int(hour):02d}:00"
            break

    # ë‚ ì§œ ì¶”ì¶œ
    date_match = re.search(r'(\d{1,2})ì›”\s*(\d{1,2})ì¼', text)
    if date_match:
        month, day = date_match.groups()
        components['date'] = f"{int(month):02d}ì›” {int(day):02d}ì¼"

    # ìš”ì¼ ì¶”ì¶œ
    for weekday_pattern, weekday_num in WEEKDAY_PATTERNS.items():
        if re.search(weekday_pattern, text):
            components['weekday'] = weekday_pattern.replace('?', '').replace('r\'', '').replace('\'', '')
            break

    # ì¥ì†Œ, ì´ë¦„ ì¶”ì¶œ
    components['location'] = extract_location_smart(text)
    components['names'] = extract_names_smart(text)

    # ì‘ê°€ ì¶”ì¶œ
    if 'ì‘ê°€' in text and components['names']:
        words = text.split()
        for i, word in enumerate(words):
            if 'ì‘ê°€' in word and i > 0:
                prev_word = words[i-1].replace('-', '').strip()
                if prev_word in components['names']:
                    components['photographer'] = prev_word
                    break

    return components

def is_meaningful_schedule(text: str, components: Dict[str, Any]) -> bool:
    """ì˜ë¯¸ìˆëŠ” ìŠ¤ì¼€ì¤„ì¸ì§€ íŒë‹¨í•˜ëŠ” íœ´ë¦¬ìŠ¤í‹±"""

    # ğŸš« í™•ì‹¤íˆ ì¼ë°˜ ë¬¸ì˜ì¸ ê²½ìš°ë“¤
    noise_patterns = [
        r'í˜¹ì‹œë‚˜.*ì—°ë½', r'ë¬¸ì˜.*ë“œë ¤', r'ì—°ë½.*ì£¼ì„¸ìš”', r'ê°€ëŠ¥.*ê²ƒ.*ìˆìœ¼ë©´',
        r'\d+ë§Œì›', r'ì´¬ì˜ë¹„', r'ì¶œì¥ë¹„', r'ì¶”ê°€.*ì…ë‹ˆë‹¤', r'ê±´ë‹¹.*ì…ë‹ˆë‹¤'
    ]

    for pattern in noise_patterns:
        if re.search(pattern, text):
            return False

    # âœ… ì‹œê°„ì´ ìˆìœ¼ë©´ì„œ ì¥ì†Œë„ ìˆëŠ” ê²½ìš° (ê°€ì¥ í™•ì‹¤í•œ ìŠ¤ì¼€ì¤„)
    if components['time'] and components['location']:
        return True

    # âœ… ì™„ì „í•œ ë‚ ì§œ ì •ë³´ê°€ ìˆìœ¼ë©´ì„œ ì‹œê°„ë„ ìˆëŠ” ê²½ìš°
    if components['date'] and components['time']:
        return True

    # âœ… ì‘ê°€ ì •ë³´ê°€ ëª…ì‹œëœ ê²½ìš° (í™•ì‹¤í•œ ìŠ¤ì¼€ì¤„)
    if components['photographer'] and (components['time'] or components['location']):
        return True

    # ğŸš« ì‹œê°„ë„ ì¥ì†Œë„ ì—†ìœ¼ë©´ ì˜ë¯¸ì—†ìŒ
    if not components['time'] and not components['location']:
        return False

    # ğŸš« ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ (5ê¸€ì ë¯¸ë§Œ)
    if len(text.strip()) < 5:
        return False

    # ğŸš« ì¼ë°˜ì ì¸ ë‹¨ì–´ë§Œ ìˆëŠ” ê²½ìš°
    meaningful_words = [word for word in text.split() if len(word) >= 2 and word not in COMMON_WORDS]
    if len(meaningful_words) < 2:
        return False

    return True

def nlp_parse_flexible_format(text: str, current_year: int = None) -> Optional[Schedule]:
    """spaCy ê¸°ë°˜ ê³ ì„±ëŠ¥ NLP ìŠ¤ì¼€ì¤„ íŒŒì‹±"""
    if not nlp or not text or len(text.strip()) < 3:
        return None

    if current_year is None:
        current_year = datetime.now().year

    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì •ê·œí™”
    normalized_text = normalize_text_spacy(text)

    # spaCyë¡œ ê°œì²´ëª… ì¶”ì¶œ
    entities = extract_entities_with_spacy(normalized_text)

    # ì˜ë¯¸ìˆëŠ” ìŠ¤ì¼€ì¤„ì¸ì§€ íŒë‹¨
    if not is_meaningful_schedule_spacy(normalized_text, entities):
        return None

    # ê° ìš”ì†Œ ì¶”ì¶œ
    date_str = extract_date_from_entities_spacy(entities, normalized_text, current_year)
    time_str = extract_time_from_entities_spacy(entities, normalized_text)
    location_str = extract_location_from_entities_spacy(entities, normalized_text)
    couple_str = extract_couple_from_entities_spacy(entities)

    # ë¸Œëœë“œ/ì•¨ë²” ì¶”ì¶œ (ì •ê·œí‘œí˜„ì‹)
    brand_str = extract_brand_from_text(normalized_text)

    # ìµœì¢… ê²€ì¦: ë‚ ì§œë‚˜ ì‹œê°„ ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
    if not date_str and not time_str:
        return None

    # ì¥ì†Œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    if not location_str and time_str:
        location_str = "ì¥ì†Œ ë¯¸ìƒ"

    # ê²€í†  í•„ìš”ì„± íŒë‹¨
    review_reasons = []
    if not date_str:
        review_reasons.append("ë‚ ì§œ ì •ë³´ ì—†ìŒ")
    if not time_str:
        review_reasons.append("ì‹œê°„ ì •ë³´ ì—†ìŒ")
    if not location_str or location_str == "ì¥ì†Œ ë¯¸ìƒ":
        review_reasons.append("ì¥ì†Œ ì •ë³´ ì—†ìŒ")
    if not couple_str:
        review_reasons.append("ì»¤í”Œ ì •ë³´ ì—†ìŒ")

    needs_review = len(review_reasons) > 0
    review_reason = f"spaCy NLP: {', '.join(review_reasons)}" if review_reasons else "spaCy NLP"

    # ì‹ ë‘ì‹ ë¶€ ì´ë¦„ ë¶„ë¦¬ ì²˜ë¦¬
    separated_couple = separate_couple_names(couple_str) if couple_str else ""

    return Schedule(
        date=date_str or "",
        location=clean_location(location_str) if location_str else "",
        time=time_str or "",
        couple=separated_couple,
        photographer="",
        manager="",
        brand=brand_str or "",
        album="",
        contact="",
        memo="",
        needs_review=needs_review,
        review_reason=review_reason
    )

def parse_flexible_format(text: str, current_year: int) -> Optional[Schedule]:
    """
    ğŸš€ ìœ ì—°í•œ ë‹¨ì–´ ì¶”ì¶œ/ì¡°í•© ë°©ì‹ íŒŒì„œ
    ë¬¸ì¥ì—ì„œ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•˜ê³  ì¡°í•©í•˜ì—¬ ìŠ¤ì¼€ì¤„ ì •ë³´ ìƒì„±

    ì˜ˆì‹œ:
    - "11ì›”29ì¼ í† ìš”ì¼ ì´¬ì˜ ìŠ¤ì¼€ì¥´ ê°€ëŠ¥ í•œ ê²ƒ ìˆìœ¼ë©´ ì—°ë½ ì£¼ì„¸ìš”"
    - "ê¹€í•´. ì°½ì›ì€ ì¶œì¥ë¹„ 5ë§Œì› ì¶”ê°€ ì…ë‹ˆë‹¤"
    - "ê¹€í•´ë©”ë¥´ì‹œì•™ 12ì‹œ"
    """
    if not text or len(text.strip()) < 3:
        return None

    # ğŸ” ë‹¨ì–´ ì¶”ì¶œ
    extracted_info = extract_schedule_components(text)

    # ğŸ“… ë‚ ì§œ ì •ë³´ ì²˜ë¦¬
    date_str = ""
    if extracted_info['date']:
        date_str = format_date_to_standard(extracted_info['date'], current_year)
    elif extracted_info['weekday']:
        # ìš”ì¼ ê¸°ë°˜ ì¶”ì¸¡
        predicted_date = get_date_from_weekday(extracted_info['weekday'])
        if predicted_date:
            try:
                month_day = predicted_date.replace('ì›”', '').replace('ì¼', '')
                month, day = month_day.split()
                month, day = int(month), int(day)
                date_str = f"{current_year}.{month:02d}.{day:02d}"
            except:
                date_str = ""

    # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ (ì´ë²ˆ ì£¼ í† ìš”ì¼)
    if not date_str:
        predicted_date = get_next_saturday()
        try:
            month_day = predicted_date.replace('ì›”', '').replace('ì¼', '')
            month, day = month_day.split()
            month, day = int(month), int(day)
            date_str = f"{current_year}.{month:02d}.{day:02d}"
        except:
            date_str = ""

    # â° ì‹œê°„ ì •ë³´ ì²˜ë¦¬
    time_str = extracted_info['time'] or ""

    # ğŸ¢ ì¥ì†Œ ì •ë³´ ì²˜ë¦¬
    location_str = extracted_info['location'] or ""

    # ğŸ‘¥ ì»¤í”Œ ì •ë³´ ì²˜ë¦¬
    couple_str = ""
    if extracted_info['names'] and len(extracted_info['names']) >= 2:
        couple_str = " ".join(extracted_info['names'][:2])  # ì²˜ìŒ ë‘ ì´ë¦„

    # ğŸ“¸ ì‘ê°€ ì •ë³´ ì²˜ë¦¬
    photographer_str = ""
    if extracted_info['photographer']:
        photographer_str = extracted_info['photographer']
    elif extracted_info['names'] and len(extracted_info['names']) >= 3:
        photographer_str = extracted_info['names'][-1]  # ë§ˆì§€ë§‰ ì´ë¦„

    # ìµœì†Œ ì¡°ê±´ í™•ì¸: ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
    if not date_str and not location_str and not time_str:
        return None

    # ìŠ¤ì¼€ì¤„ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë” ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬
    schedule_keywords = ['ìŠ¤ì¼€ì¤„', 'ì´¬ì˜', 'ê°€ëŠ¥', 'ì—°ë½', 'ì˜ˆì•½']
    has_schedule_keyword = any(keyword in text.lower() for keyword in schedule_keywords)

    if has_schedule_keyword and not location_str and not time_str:
        location_str = "ì¼ë°˜ ë¬¸ì˜"  # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì„ì‹œ ì¥ì†Œ ì„¤ì •

    # ğŸ”§ ê²€í†  ì´ìœ  ìƒì„±
    review_reasons = []
    if not date_str:
        review_reasons.append("ë‚ ì§œ ì¶”ì¸¡ë¨")
    if not couple_str:
        review_reasons.append("ì»¤í”Œ ì •ë³´ ì—†ìŒ")
    if not photographer_str:
        review_reasons.append("ì‘ê°€ ì •ë³´ ì—†ìŒ")
    if not location_str:
        review_reasons.append("ì¥ì†Œ ì •ë³´ ì—†ìŒ")

    review_reason = f"ìœ ì—°í•œ íŒŒì„œ: {', '.join(review_reasons)}" if review_reasons else ""

    # ì‹ ë‘ì‹ ë¶€ ì´ë¦„ ë¶„ë¦¬ ì²˜ë¦¬
    separated_couple = separate_couple_names(couple_str) if couple_str else ""

    return Schedule(
        date=date_str,
        location=clean_location(location_str),
        time=time_str,
        couple=separated_couple,
        photographer=photographer_str,
        manager="", brand="", album="", contact="", memo="",
        needs_review=True,
        review_reason=review_reason
    )

def extract_schedule_components(text: str) -> Dict[str, Any]:
    """
    ğŸ” ë¬¸ì¥ì—ì„œ ìŠ¤ì¼€ì¤„ êµ¬ì„± ìš”ì†Œë“¤ì„ ì¶”ì¶œ
    """
    components = {
        'date': None,
        'weekday': None,
        'time': None,
        'location': None,
        'names': [],
        'photographer': None
    }

    # ğŸ“… ë‚ ì§œ ì¶”ì¶œ
    date_patterns = [
        r'(\d{1,2})ì›”(\d{1,2})ì¼',  # MMì›”DDì¼
        r'(\d{4})[-./](\d{1,2})[-./](\d{1,2})',  # YYYY-MM-DD
        r'(\d{1,2})[-./](\d{1,2})'  # MM-DD
    ]
    for pattern in date_patterns:
        match = re.search(pattern, text)
        if match:
            components['date'] = match.group(0)
            break

    # ğŸ“† ìš”ì¼ ì¶”ì¶œ
    weekday_match = re.search(r'([ê°€-í£]ìš”ì¼?)', text)
    if weekday_match:
        components['weekday'] = weekday_match.group(1)

    # â° ì‹œê°„ ì¶”ì¶œ
    time_patterns = [
        r'(\d{1,2}):(\d{2})',  # HH:MM
        r'(\d{1,2})ì‹œ(\d{1,2})ë¶„',  # HHì‹œMMë¶„
        r'(\d{1,2})ì‹œ(?!ê°„)',  # HHì‹œ (ì‹œê°„ì´ ì•„ë‹Œ ê²½ìš°)
    ]
    for pattern in time_patterns:
        match = re.search(pattern, text)
        if match:
            if len(match.groups()) == 2:
                hour, minute = match.groups()
                components['time'] = f"{int(hour):02d}:{int(minute):02d}"
            else:
                hour = match.group(1)
                components['time'] = f"{int(hour):02d}:00"
            break

    # ğŸ¢ ì¥ì†Œ ì¶”ì¶œ (í•œê¸€ ì¥ì†Œëª…)
    venue_patterns = [
        r'([ê°€-í£]{2,}(?:í˜¸í…”|ì„¼í„°|ì»¨ë²¤ì…˜|ì›¨ë”©í™€|êµíšŒ|ì„±ë‹¹|ì˜ˆì‹ì¥|ë¦¬ì¡°íŠ¸|íœì…˜))',
        r'([ê°€-í£]{2,}(?:ë©”ë¥´ì‹œì•™|ê·¸ëœë“œ|ì¡°ì„ |ë¡¯ë°|ì‹ ë¼|í•˜ì–íŠ¸|ííŠ¼))',
        r'([ê°€-í£]+(?:\s*["\']?[a-zA-Z0-9ê°€-í£]+["\']?)?(?:í™€|ë£¸|ê´€|ë™))',
    ]
    for pattern in venue_patterns:
        matches = re.findall(pattern, text)
        if matches:
            components['location'] = matches[0]
            break

    # ğŸ¢ ì§€ì—­ëª… ê¸°ë°˜ ì¥ì†Œ ì¶”ì¶œ
    if not components['location']:
        location_pattern = r'(ê¹€í•´|ì°½ì›|ë¶€ì‚°|í•´ìš´ëŒ€|ì„¼í…€|ê´‘ì£¼|ëŒ€êµ¬|ì„œìš¸|ì¸ì²œ|ëŒ€ì „)(?:\s*[ê°€-í£]*)?'
        location_match = re.search(location_pattern, text)
        if location_match:
            components['location'] = location_match.group(0).strip()

    # ğŸ¢ ì¼ë°˜ì ì¸ ì¥ì†Œ í‚¤ì›Œë“œë“¤ ì¶”ì¶œ
    if not components['location']:
        general_venue_keywords = ['ì´¬ì˜', 'ìŠ¤ì¼€ì¤„', 'ì›¨ë”©', 'ì˜ˆì‹']
        for keyword in general_venue_keywords:
            if keyword in text:
                components['location'] = f'{keyword} ê´€ë ¨'
                break

    # ğŸ‘¥ ì¸ëª… ì¶”ì¶œ (í•œê¸€ 2-4ê¸€ì)
    name_patterns = [
        r'([ê°€-í£]{2,4})\s+([ê°€-í£]{2,4})\s*-\s*([ê°€-í£]+)\s*ì‘ê°€',  # ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€
        r'([ê°€-í£]{2,4})',  # ì¼ë°˜ì ì¸ í•œê¸€ ì´ë¦„
    ]

    # ì‘ê°€ íŒ¨í„´ ìš°ì„  í™•ì¸
    photographer_match = re.search(r'([ê°€-í£]+)\s*ì‘ê°€', text)
    if photographer_match:
        components['photographer'] = photographer_match.group(1)

    # ì¼ë°˜ ì´ë¦„ë“¤ ì¶”ì¶œ
    names = []
    for name_match in re.finditer(r'[ê°€-í£]{2,4}', text):
        name = name_match.group(0)
        # ì¼ë°˜ì ì´ì§€ ì•Šì€ ë‹¨ì–´ë“¤ ì œì™¸
        if name not in ['ìŠ¤ì¼€ì¤„', 'ì´¬ì˜', 'ì—°ë½', 'ì¶œì¥ë¹„', 'ë§Œì›', 'ì¶”ê°€', 'ì…ë‹ˆë‹¤', 'ìˆìœ¼ë©´', 'ì£¼ì„¸ìš”', 'ê°€ëŠ¥']:
            names.append(name)

    components['names'] = list(set(names))  # ì¤‘ë³µ ì œê±°

    return components

def format_date_to_standard(date_str: str, current_year: int) -> str:
    """ë‚ ì§œ ë¬¸ìì—´ì„ YYYY.MM.DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        # MMì›”DDì¼ í˜•ì‹
        if 'ì›”' in date_str and 'ì¼' in date_str:
            date_clean = date_str.replace('ì›”', '').replace('ì¼', '')
            if ' ' in date_clean:
                month, day = date_clean.split()
            else:
                # 11ì›”29ì¼ ê°™ì€ í˜•ì‹ì—ì„œ ìˆ«ì ë¶„ë¦¬
                match = re.match(r'(\d{1,2})(\d{1,2})$', date_clean)
                if match and len(date_clean) <= 4:
                    month, day = match.groups()
                else:
                    return ""

            month, day = int(month), int(day)
            return f"{current_year}.{month:02d}.{day:02d}"

        # YYYY-MM-DD ë˜ëŠ” MM-DD í˜•ì‹
        elif '-' in date_str or '.' in date_str or '/' in date_str:
            parts = re.split(r'[-./]', date_str)
            if len(parts) == 3:
                return f"{parts[0]}.{int(parts[1]):02d}.{int(parts[2]):02d}"
            elif len(parts) == 2:
                return f"{current_year}.{int(parts[0]):02d}.{int(parts[1]):02d}"
    except:
        pass

    return ""

def split_chat_by_speaker(raw_text: str) -> List[Tuple[str, str]]:
    """
    Splits the raw chat log into blocks per speaker turn.
    Automatically detects format (desktop/mobile) and uses appropriate parser.
    """
    chat_format = detect_chat_format(raw_text)

    if chat_format == 'compact':
        # Compact format doesn't have speakers, return empty list
        return []
    elif chat_format == 'desktop':
        return split_chat_by_speaker_desktop(raw_text)
    elif chat_format == 'mobile':
        return split_chat_by_speaker_mobile(raw_text)
    else:
        # Fallback to desktop format for backward compatibility
        return split_chat_by_speaker_desktop(raw_text)

def find_manager_speaker(speaker_blocks: List[Tuple[str, str]]) -> str:
    """Find the most likely manager speaker by analyzing content patterns."""
    # Look for speakers with schedule-like content (dates, venues, etc.)
    speaker_schedule_counts = {}

    for speaker, content in speaker_blocks:
        schedule_indicators = 0
        lines = content.split('\n')

        for line in lines:
            line = line.strip()
            # Count date patterns
            if re.match(r'^\d{4}\.\d{2}\.\d{2}$', line):
                schedule_indicators += 3  # High weight for dates
            # Count time patterns
            elif re.match(r'^\d{2}:\d{2}$', line):
                schedule_indicators += 2  # Medium weight for times
            # Count brand patterns
            elif any(re.search(pattern, line) for pattern in BRAND_PATTERNS):
                schedule_indicators += 2  # Medium weight for brands
            # Count location-like patterns (contains í™€, ì¸µ, etc.)
            elif any(keyword in line for keyword in ['í™€', 'ì¸µ', 'ì»¨ë²¤ì…˜', 'ì›¨ë”©', 'ë”']):
                schedule_indicators += 1  # Low weight for venues

        if schedule_indicators > 0:
            speaker_schedule_counts[speaker] = schedule_indicators

    # Return the speaker with the most schedule-like content
    if speaker_schedule_counts:
        return max(speaker_schedule_counts, key=speaker_schedule_counts.get)

    # Fallback to MANAGER_NAME if no clear manager found
    return MANAGER_NAME

def parse_manager_block(block_text: str) -> List[Schedule]:
    """Parses a single text block from the manager, which might contain multiple schedules."""
    schedules = []
    current_year = datetime.now().year  # NLP íŒŒì„œìš© í˜„ì¬ ì—°ë„
    lines = [line.strip() for line in block_text.splitlines() if line.strip() and not line.startswith('---')]
    
    # Find all schedule start indices (line 1 of the 4-line core)
    start_indices = []
    for i, line in enumerate(lines):
        if is_valid_date(line):
            start_indices.append(i)
            # Extract and use the clean date
            clean_date = extract_date(line)
            if clean_date:
                lines[i] = clean_date


    # ì¼ë°˜ì ì¸ ìŠ¤ì¼€ì¤„ íŒ¨í„´ì´ ì—†ìœ¼ë©´ NLP íŒŒì„œë¡œ ì „ì²´ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    if not start_indices:
        try:
            extracted_schedule = nlp_parse_flexible_format(block_text, current_year)
            if extracted_schedule:
                return [extracted_schedule]
        except Exception as e:
            pass
        return []

    for i, start_idx in enumerate(start_indices):
        # Determine the end of the current schedule block
        end_idx = start_indices[i+1] if (i + 1) < len(start_indices) else len(lines)
        schedule_lines = lines[start_idx:end_idx]

        if len(schedule_lines) < 4: continue

        # Core 4-line block validation
        date, location, time, couple = schedule_lines[0], schedule_lines[1], schedule_lines[2], schedule_lines[3]
        if not (is_valid_date(date) and is_valid_time(time) and is_valid_couple(couple)):
            continue

        # ì‹ ë‘ì‹ ë¶€ ì´ë¦„ ë¶„ë¦¬ ì²˜ë¦¬
        separated_couple = separate_couple_names(couple)
        sch = Schedule(date=date, location=clean_location(location), time=time, couple=separated_couple)
        
        # Subtractive parsing on the rest of the lines
        remaining_lines = schedule_lines[4:]
        processed_indices = set()

        if remaining_lines:
            sch.manager = remaining_lines.pop(-1).strip()
            # Standardize contractor names
            if 'ê·¸ëœë“œ ë¸”ë‘' in sch.manager:
                sch.manager = sch.manager.replace('ê·¸ëœë“œ ë¸”ë‘', 'ê·¸ëœë“œë¸”ë‘')

        # First, check for contact number in the first line only (right after couple names)
        if remaining_lines:
            contact = parse_contact(remaining_lines[0])
            if contact:
                sch.contact = contact
                processed_indices.add(0)

        j = 0
        while j < len(remaining_lines):
            line = remaining_lines[j]
            is_known_pattern = False

            # Skip contact parsing since we already handled it above
            if j == 0 and sch.contact:
                is_known_pattern = True

            brand, album = parse_brand_album(line)
            if brand or album:
                if brand: sch.brand = brand
                if album: sch.album = album
                processed_indices.add(j); is_known_pattern = True

            # Extract photographer name by removing contact and role info
            name_part = re.sub(r'010[- .]?\d{4}[- .]?\d{4}', '', line).strip()
            name_part = re.sub(r'\([^)]*\)', '', name_part).strip()  # Remove parentheses content like (ë©”ì¸), (ì„œë¸Œ)
            name_part = re.sub(r'â€­|â€¬', '', name_part).strip()  # Remove invisible characters

            if is_valid_photographer_name(name_part):
                photographers = [name_part]
                processed_indices.add(j); is_known_pattern = True

                # Check next line for additional photographer
                if (j + 1) < len(remaining_lines):
                    next_line = remaining_lines[j+1]
                    next_name_part = re.sub(r'010[- .]?\d{4}[- .]?\d{4}', '', next_line).strip()
                    next_name_part = re.sub(r'\([^)]*\)', '', next_name_part).strip()
                    next_name_part = re.sub(r'â€­|â€¬', '', next_name_part).strip()

                    if is_valid_photographer_name(next_name_part):
                        photographers.append(next_name_part)
                        processed_indices.add(j + 1)
                        j += 1  # Skip next line since we processed it

                sch.photographer = ", ".join(photographers)
                is_known_pattern = True

            # Only mark as needs_review if line is not empty and not a known pattern
            # We'll handle comments content separately
            if not is_known_pattern and line.strip():
                sch.needs_review = True
                if not sch.review_reason:
                    sch.review_reason = "ì•Œ ìˆ˜ ì—†ëŠ” ë‚´ìš©"

            j += 1

        # Create comments from unprocessed lines
        sch.memo = "\n".join(remaining_lines[k] for k in range(len(remaining_lines)) if k not in processed_indices).strip()

        # If we have comments content, it means there were unprocessed lines
        # Reset needs_review to False since comments content is intentional
        if sch.memo:
            sch.needs_review = False
            sch.review_reason = ""

        # Mark for review if critical fields are missing
        missing_fields = []
        if not sch.brand: missing_fields.append("ë¸Œëœë“œ")
        if not sch.album: missing_fields.append("ì•¨ë²”")
        if not sch.photographer: missing_fields.append("ì‘ê°€")
        if not sch.manager: missing_fields.append("ê³„ì•½ì")

        if missing_fields:
            sch.needs_review = True
            sch.review_reason = f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {', '.join(missing_fields)}"

        # ì´¬ì˜ë‹¨ê°€ ìë™ ê³„ì‚° (íŒŒì‹±í•  ë•Œë§Œ)
        if sch.brand and sch.album and sch.date:
            sch.price = calculate_price(sch.brand, sch.album, sch.date)

        schedules.append(sch)

    return schedules

def get_schedule_completeness_score(schedule: Schedule) -> int:
    """Calculate completeness score for data integrity comparison."""
    score = 0

    # Core fields (must exist for basic validity)
    if schedule.date and extract_date(schedule.date): score += 10
    if schedule.location: score += 5
    if schedule.time and is_valid_time(schedule.time): score += 10
    if schedule.couple and is_valid_couple(schedule.couple): score += 10

    # Critical fields for business logic
    if schedule.brand: score += 8
    if schedule.album: score += 8
    if schedule.photographer: score += 8
    if schedule.manager: score += 8

    # Optional but valuable fields
    if schedule.contact and parse_contact(schedule.contact): score += 5
    if schedule.memo: score += 2

    return score

def is_better_schedule(existing: Schedule, new: Schedule) -> bool:
    """
    Determine if new schedule is better than existing one.
    Returns True if new schedule should replace existing one.
    """
    existing_score = get_schedule_completeness_score(existing)
    new_score = get_schedule_completeness_score(new)

    # If new schedule has significantly higher completeness, use it
    if new_score > existing_score:
        return True

    # If scores are equal, prefer the one without needs_review flag
    if new_score == existing_score:
        if existing.needs_review and not new.needs_review:
            return True
        # If both have same review status, prefer the new one (latest wins for ties)
        if existing.needs_review == new.needs_review:
            return True
        return False

    # If new score is lower, keep existing
    return False

def calculate_price(brand: str, album: str, date: str) -> int:
    """
    ë¸Œëœë“œì™€ ì•¨ë²”, ë‚ ì§œì— ë”°ë¼ ì´¬ì˜ë‹¨ê°€ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        brand: ë¸Œëœë“œëª… (Kì„¸ë¸ìŠ¤, Bì„¸ë¸ìŠ¤, Aì„¸ë¸ìŠ¤í”„ë¦¬ë¯¸ì—„, ë”ê·¸ë¼í”¼, ì„¸ì»¨í”Œë¡œìš°)
        album: ì•¨ë²” íƒ€ì… (30P, 40P, 50P ë“±)
        date: ì´¬ì˜ ë‚ ì§œ (YYYY.MM.DD í˜•ì‹)

    Returns:
        int: ì´¬ì˜ë‹¨ê°€ (ìˆ«ìë§Œ)
    """
    try:
        # ë‚ ì§œ íŒŒì‹± (2025.09.01 ê¸°ì¤€ ë‹¨ê°€ ë³€ê²½)
        schedule_date = datetime.strptime(date, '%Y.%m.%d')
        price_change_date = datetime(2025, 9, 1)
        is_after_sep_2025 = schedule_date >= price_change_date

        # ë¸Œëœë“œëª… ì •ê·œí™”
        brand_lower = brand.lower().replace(' ', '').replace('[', '').replace(']', '')

        # ì•¨ë²”ì—ì„œ ìˆ«ì ì¶”ì¶œ (30P, 40P, 50P ë“±)
        album_match = re.search(r'(\d+)[Pp]', album)
        album_pages = int(album_match.group(1)) if album_match else 30

        # Kì„¸ë¸ìŠ¤
        if 'kì„¸ë¸ìŠ¤' in brand_lower:
            return 140000 if is_after_sep_2025 else 150000

        # Bì„¸ë¸ìŠ¤ (Kì„¸ë¸ìŠ¤ + 2ë§Œì›)
        elif 'bì„¸ë¸ìŠ¤' in brand_lower:
            k_price = 140000 if is_after_sep_2025 else 150000
            return k_price + 20000

        # Aì„¸ë¸ìŠ¤í”„ë¦¬ë¯¸ì—„
        elif 'aì„¸ë¸ìŠ¤í”„ë¦¬ë¯¸ì—„' in brand_lower:
            return 190000

        # ë”ê·¸ë¼í”¼, ì„¸ì»¨í”Œë¡œìš°
        elif 'ë”ê·¸ë¼í”¼' in brand_lower or 'ì„¸ì»¨í”Œë¡œìš°' in brand_lower:
            if album_pages <= 30:
                return 170000
            elif album_pages <= 40:
                return 190000 if is_after_sep_2025 else 200000
            elif album_pages >= 50:
                return 240000 if is_after_sep_2025 else 250000
            else:
                return 170000  # ê¸°ë³¸ê°’

        # ì•Œ ìˆ˜ ì—†ëŠ” ë¸Œëœë“œ
        else:
            return 0

    except (ValueError, AttributeError):
        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return 0

def parse_schedules(raw_text: str) -> List[Dict]:
    """Main entry point for parsing schedules from a raw chat log."""
    # Detect format first
    chat_format = detect_chat_format(raw_text)

    # Handle compact format directly
    if chat_format == 'compact':
        parsed_schedules = parse_compact_format(raw_text)
        return [sch.to_dict() for sch in parsed_schedules]

    # Handle chat formats (desktop/mobile)
    speaker_blocks = split_chat_by_speaker(raw_text)

    # If no speaker blocks found (plain text input), treat the whole text as one block
    if not speaker_blocks:
        parsed_schedules = parse_manager_block(raw_text)
        return [sch.to_dict() for sch in parsed_schedules]

    # Automatically find the manager speaker
    manager_speaker = find_manager_speaker(speaker_blocks)

    # Use a dictionary to handle duplicates and merge if necessary
    final_schedules: Dict[str, Schedule] = {}

    for speaker, content in speaker_blocks:
        if speaker == manager_speaker:
            parsed_schedules = parse_manager_block(content)
            for sch in parsed_schedules:
                key = f"{sch.date}-{sch.time}-{sch.couple}"

                if key not in final_schedules:
                    # First occurrence, just add it
                    final_schedules[key] = sch
                else:
                    # Duplicate found, compare and choose better one
                    if is_better_schedule(final_schedules[key], sch):
                        final_schedules[key] = sch

    return [sch.to_dict() for sch in final_schedules.values()]


# === spaCy NLP Helper Functions ===

def normalize_text_spacy(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì •ê·œí™”"""
    # ì´ëª¨í‹°ì½˜ ì œê±°
    text = re.sub(r'[ğŸ‰ğŸ“ğŸ‘°ğŸ»ğŸ¤µğŸ»ğŸ“¸ğŸ’•ğŸ’°â­ï¸]', '', text)

    # ì˜¤íƒ€ ìˆ˜ì •
    typo_fixes = {
        'ì•Œë²”': 'ì•¨ë²”',
        'ê·¸ë˜í”¼': 'ê·¸ë˜í”¼',
        'ì˜¤í›„3ì‹œ': 'ì˜¤í›„ 3ì‹œ',
        '2ì‹œë°˜': '2ì‹œ30ë¶„',
        'í•´ë³´ì´ì†Œ': 'í•´ë³´ì„¸ìš”'
    }

    for typo, correct in typo_fixes.items():
        text = text.replace(typo, correct)

    # ë„ì–´ì“°ê¸° ì •ê·œí™” (ë‚ ì§œ, ì‹œê°„ ê´€ë ¨)
    text = re.sub(r'(\d+ì›”)(\d+ì¼)', r'\1 \2', text)
    text = re.sub(r'(\d+ì¼)(í† ìš”ì¼|ì¼ìš”ì¼|ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼)', r'\1 \2', text)
    text = re.sub(r'(ì˜¤ì „|ì˜¤í›„)(\d+ì‹œ)', r'\1 \2', text)
    text = re.sub(r'(\d+ì‹œ)(\d+ë¶„)', r'\1\2', text)

    return text.strip()

def extract_entities_with_spacy(text: str) -> Dict[str, List[str]]:
    """spaCyë¥¼ ì‚¬ìš©í•œ ê°œì²´ëª… ì¶”ì¶œ"""
    if not nlp:
        return {}

    doc = nlp(text)

    entities = {
        'persons': [],      # PS (ì¸ëª…)
        'locations': [],    # LC (ì§€ëª…), OG (ì¡°ì§/ì¥ì†Œëª…)
        'dates': [],        # DT (ë‚ ì§œ)
        'times': [],        # TI (ì‹œê°„)
        'quantities': []    # QT (ìˆ˜ëŸ‰/ë²ˆí˜¸)
    }

    for ent in doc.ents:
        if ent.label_ == 'PS':  # ì¸ëª…
            entities['persons'].append(ent.text)
        elif ent.label_ in ['LC', 'OG']:  # ì§€ëª…, ì¡°ì§ëª…
            entities['locations'].append(ent.text)
        elif ent.label_ == 'DT':  # ë‚ ì§œ
            entities['dates'].append(ent.text)
        elif ent.label_ == 'TI':  # ì‹œê°„
            entities['times'].append(ent.text)
        elif ent.label_ == 'QT':  # ìˆ˜ëŸ‰
            entities['quantities'].append(ent.text)

    return entities

def extract_date_from_entities_spacy(entities: Dict[str, List[str]], text: str, current_year: int) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ ë° ì •ê·œí™”"""
    # spaCyê°€ ì¸ì‹í•œ ë‚ ì§œ ê°œì²´ ìš°ì„  ì²˜ë¦¬
    for date_ent in entities.get('dates', []):
        # "ë‚´ì¼", "ì˜¤ëŠ˜", "ëª¨ë ˆ" ë“± ìƒëŒ€ì  ë‚ ì§œ
        if 'ë‚´ì¼' in date_ent:
            tomorrow = datetime.now() + timedelta(days=1)
            return tomorrow.strftime('%Y.%m.%d')
        elif 'ì˜¤ëŠ˜' in date_ent:
            return datetime.now().strftime('%Y.%m.%d')
        elif 'ëª¨ë ˆ' in date_ent:
            day_after_tomorrow = datetime.now() + timedelta(days=2)
            return day_after_tomorrow.strftime('%Y.%m.%d')

    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ (ë°±ì—…)
    date_patterns = [
        r'(\d{1,2})ì›”\s*(\d{1,2})ì¼',
        r'(\d{4})[.\-/](\d{1,2})[.\-/](\d{1,2})',
        r'(\d{1,2})[.\-/](\d{1,2})'
    ]

    for pattern in date_patterns:
        match = re.search(pattern, text)
        if match:
            if len(match.groups()) == 2:  # MMì›” DDì¼ í˜•íƒœ
                month, day = match.groups()
                return f"{current_year}.{int(month):02d}.{int(day):02d}"
            elif len(match.groups()) == 3:  # YYYY.MM.DD í˜•íƒœ
                year, month, day = match.groups()
                return f"{year}.{int(month):02d}.{int(day):02d}"

    # ìš”ì¼ ê¸°ë°˜ ë‚ ì§œ ì¶”ì¸¡
    weekdays = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
    for i, weekday in enumerate(weekdays):
        if weekday in text:
            # ê°€ì¥ ê°€ê¹Œìš´ í•´ë‹¹ ìš”ì¼ ì°¾ê¸°
            today = datetime.now()
            days_ahead = i - today.weekday()
            if days_ahead <= 0:  # ì´ë¯¸ ì§€ë‚¬ê±°ë‚˜ ì˜¤ëŠ˜ì´ë©´ ë‹¤ìŒ ì£¼
                days_ahead += 7
            target_date = today + timedelta(days=days_ahead)
            return target_date.strftime('%Y.%m.%d')

    return None

def extract_time_from_entities_spacy(entities: Dict[str, List[str]], text: str) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ì‹œê°„ ì¶”ì¶œ ë° ì •ê·œí™”"""
    # spaCyê°€ ì¸ì‹í•œ ì‹œê°„ ê°œì²´ ìš°ì„  ì²˜ë¦¬
    for time_ent in entities.get('times', []):
        # "ì˜¤í›„ 2ì‹œë°˜ì—" -> "14:30"
        time_match = re.search(r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ(\d{1,2}ë¶„|ë°˜)?', time_ent)
        if time_match:
            period, hour, minute_part = time_match.groups()
            hour = int(hour)

            if period == 'ì˜¤í›„' and hour != 12:
                hour += 12
            elif period == 'ì˜¤ì „' and hour == 12:
                hour = 0

            if minute_part == 'ë°˜':
                minute = 30
            elif minute_part and 'ë¶„' in minute_part:
                minute = int(minute_part.replace('ë¶„', ''))
            else:
                minute = 0

            return f"{hour:02d}:{minute:02d}"

    # ì •ê·œí‘œí˜„ì‹ ë°±ì—…
    time_patterns = [
        r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ\s*(\d{1,2})ë¶„',
        r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œë°˜',
        r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ',
        r'(\d{1,2}):(\d{2})'
    ]

    for pattern in time_patterns:
        match = re.search(pattern, text)
        if match:
            groups = match.groups()
            if len(groups) == 3 and groups[2]:  # ì˜¤ì „/ì˜¤í›„ + ì‹œ + ë¶„
                period, hour, minute = groups
                hour, minute = int(hour), int(minute)
            elif len(groups) == 2 and groups[0] in ['ì˜¤ì „', 'ì˜¤í›„']:  # ì˜¤ì „/ì˜¤í›„ + ì‹œë°˜
                period, hour = groups
                hour, minute = int(hour), 30
            elif len(groups) == 2 and groups[0].isdigit():  # HH:MM
                hour, minute = int(groups[0]), int(groups[1])
                period = None
            else:
                continue

            if period == 'ì˜¤í›„' and hour != 12:
                hour += 12
            elif period == 'ì˜¤ì „' and hour == 12:
                hour = 0

            return f"{hour:02d}:{minute:02d}"

    return None

def extract_location_from_entities_spacy(entities: Dict[str, List[str]], text: str) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ì¥ì†Œ ì¶”ì¶œ"""
    # spaCyê°€ ì¸ì‹í•œ ì§€ëª…/ì¡°ì§ëª… ìš°ì„  ì‚¬ìš©
    for location in entities.get('locations', []):
        # í˜¸í…”, ì›¨ë”©í™€ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš° ìš°ì„ 
        if any(keyword in location for keyword in ['í˜¸í…”', 'ì›¨ë”©í™€', 'ì»¨ë²¤ì…˜', 'ì„¼í„°', 'í”Œë ˆì´ìŠ¤']):
            return location.replace('ì—ì„œ', '').replace('ì—', '').strip()

    # ì²« ë²ˆì§¸ ì§€ëª…/ì¡°ì§ëª… ì‚¬ìš©
    if entities.get('locations'):
        return entities['locations'][0].replace('ì—ì„œ', '').replace('ì—', '').strip()

    # ì •ê·œí‘œí˜„ì‹ ë°±ì—…
    venue_patterns = [
        r'([ê°€-í£\s]+(?:í˜¸í…”|ì›¨ë”©í™€|ì»¨ë²¤ì…˜|ì„¼í„°|í”Œë ˆì´ìŠ¤|ì±„í”Œ))',
        r'([ê°€-í£]+\s*[ê°€-í£]*(?:í˜¸í…”|ì›¨ë”©í™€))'
    ]

    for pattern in venue_patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()

    return None

def extract_couple_from_entities_spacy(entities: Dict[str, List[str]]) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ì‹ ë‘ì‹ ë¶€ ì¶”ì¶œ"""
    persons = entities.get('persons', [])
    if len(persons) >= 2:
        # ë‘ ëª… ì´ìƒì˜ ì¸ëª…ì´ ìˆìœ¼ë©´ ì‹ ë‘ì‹ ë¶€ë¡œ ê°„ì£¼
        return ' '.join(persons[:2])
    elif len(persons) == 1:
        return persons[0]

    return None

def extract_brand_from_text(text: str) -> Optional[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë¸Œëœë“œ/ì•¨ë²” ì¶”ì¶œ"""
    brand_patterns = [
        r'ì•¨ë²”[:\s]*([ê°€-í£A-Za-z\s\-]+)',
        r'ë¸Œëœë“œ[:\s]*([ê°€-í£A-Za-z\s\-]+)',
        r'(ê·¸ë˜í”¼|Kì„¸ë¸ìŠ¤|ë¹„ì„¸ë¸ìŠ¤|ì—ì´í”„ë¦¬ë¯¸ì—„|ì„¸ì»¨ë“œí”Œë¡œìš°)'
    ]

    for pattern in brand_patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()

    return None

def is_meaningful_schedule_spacy(text: str, entities: Dict[str, List[str]]) -> bool:
    """spaCy ê¸°ë°˜ ì˜ë¯¸ìˆëŠ” ìŠ¤ì¼€ì¤„ íŒë‹¨"""
    # ë…¸ì´ì¦ˆ íŒ¨í„´ (ì·¨ì†Œ, ë¬¸ì˜, ì¼ë°˜ì ì¸ ëŒ€í™”)
    noise_patterns = [
        r'ì·¨ì†Œ', r'ì£„ì†¡', r'ë‹¤ì‹œ ì—°ë½', r'ë¬¸ì˜.*ë“œë ¤', r'í˜¹ì‹œë‚˜',
        r'ê°€ëŠ¥í•œ ë‚ ', r'ëŒ€ëµì ì¸', r'ì–¼ë§ˆì¸ì§€', r'ë¹„ìš©.*ê¶ê¸ˆ'
    ]

    for pattern in noise_patterns:
        if re.search(pattern, text):
            return False

    # í•µì‹¬ ìŠ¤ì¼€ì¤„ ìš”ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸
    has_date = bool(entities.get('dates')) or any(keyword in text for keyword in ['ë‚´ì¼', 'ì˜¤ëŠ˜', 'ì¼ìš”ì¼', 'í† ìš”ì¼', 'ì›”ìš”ì¼'])
    has_time = bool(entities.get('times')) or bool(re.search(r'\d+ì‹œ', text))
    has_venue = bool(entities.get('locations'))

    # ìµœì†Œ 2ê°œ ì´ìƒì˜ í•µì‹¬ ìš”ì†Œê°€ ìˆì–´ì•¼ ì˜ë¯¸ìˆëŠ” ìŠ¤ì¼€ì¤„
    core_elements = sum([has_date, has_time, has_venue])

    return core_elements >= 2


# === Parser Engine Selection Functions ===

def has_required_fields(schedule: Dict) -> bool:
    """
    í•„ìˆ˜ í•„ë“œ 4ê°œ(ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ, ì‹ ë‘ì‹ ë¶€)ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸

    Args:
        schedule: ê²€ì¦í•  ìŠ¤ì¼€ì¤„ ë”•ì…”ë„ˆë¦¬

    Returns:
        bool: í•„ìˆ˜ í•„ë“œê°€ ëª¨ë‘ ìˆìœ¼ë©´ True, í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ False
    """
    return bool(
        schedule.get('date') and
        schedule.get('time') and
        schedule.get('location') and
        schedule.get('couple')
    )

def parse_schedules_hybrid_llm(raw_text: str) -> List[Dict]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ íŒŒì„œ (Classic + GPT-4)
    ë¨¼ì € Classic íŒŒì„œë¥¼ ì‹œë„í•˜ê³ , í•„ìˆ˜ í•„ë“œ 4ê°œ(ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ, ì‹ ë‘ì‹ ë¶€)ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìœ¼ë©´ GPT-4 íŒŒì„œë¡œ fallback
    """
    import logging
    logger = logging.getLogger(__name__)

    # ë¨¼ì € Classic ì‹œë„
    logger.info("Hybrid: Trying Classic parser first...")
    classic_result = parse_schedules_classic_only(raw_text)

    # Classicì´ ì„±ê³µí–ˆìœ¼ë©´ í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if classic_result and len(classic_result) > 0:
        # ì—ëŸ¬ ì‘ë‹µì´ ì•„ë‹Œì§€ í™•ì¸
        if not isinstance(classic_result, dict) or not classic_result.get('error'):
            # ëª¨ë“  ìŠ¤ì¼€ì¤„ì´ í•„ìˆ˜ í•„ë“œ 4ê°œ(ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ, ì‹ ë‘ì‹ ë¶€)ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
            all_have_required = all(has_required_fields(sch) for sch in classic_result)

            if all_have_required:
                logger.info(f"Hybrid: Classic parser succeeded with {len(classic_result)} schedules (all have required fields)")
                return classic_result
            else:
                # í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ìŠ¤ì¼€ì¤„ ë¡œê¹…
                missing_count = sum(1 for sch in classic_result if not has_required_fields(sch))
                logger.info(f"Hybrid: Classic parser returned {len(classic_result)} schedules, but {missing_count} are missing required fields")

    # Classicì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ê²½ìš° GPT-4 ì‹œë„
    logger.info("Hybrid: Classic parser failed or missing required fields. Falling back to GPT-4...")
    return parse_schedules_llm(raw_text)

def parse_schedules_llm(raw_text: str) -> List[Dict]:
    """
    GPT-4 ê¸°ë°˜ íŒŒì„œ (OpenAI GPT-4.1-nano)
    GPT-4ê°€ Classic parser í˜•ì‹ìœ¼ë¡œ ë³€í™˜ â†’ Classic parserê°€ ì¦‰ì‹œ ì¬íŒŒì‹±
    """
    try:
        from services.llm_parser import parse_with_llm
        import asyncio
        import logging
        logger = logging.getLogger(__name__)

        # async í•¨ìˆ˜ ì‹¤í–‰: GPT-4ê°€ Classic parser í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        converted_text = loop.run_until_complete(parse_with_llm(raw_text))
        loop.close()

        if not converted_text:
            logger.error("GPT-4 conversion returned empty result")
            return []

        logger.info(f"GPT-4 converted text to Classic format ({len(converted_text)} chars)")
        logger.debug(f"Converted text:\n{converted_text}")

        # Classic parserë¡œ ì¦‰ì‹œ ì¬íŒŒì‹±
        logger.info("Re-parsing with Classic parser...")
        parsed_schedules = parse_schedules_classic_only(converted_text)

        logger.info(f"Classic parser found {len(parsed_schedules)} schedules")
        return parsed_schedules

    except ImportError:
        return {"error": "LLM íŒŒì„œë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.", "success": False}
    except Exception as e:
        return {"error": f"LLM íŒŒì„œ ì˜¤ë¥˜: {str(e)}", "success": False}

def parse_schedules_classic_only(raw_text: str) -> List[Dict]:
    """í´ë˜ì‹ íŒŒì„œë§Œ ì‚¬ìš© (íŒ¨í„´ 1-3ë§Œ, NLP ë¹„í™œì„±í™”)"""
    chat_format = detect_chat_format(raw_text)

    if chat_format == 'compact':
        parsed_schedules = parse_compact_format(raw_text)
        return [sch.to_dict() for sch in parsed_schedules]

    speaker_blocks = split_chat_by_speaker(raw_text)

    if not speaker_blocks:
        # ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ ê²½ìš° í´ë˜ì‹ íŒ¨í„´ë§Œ ì‹œë„
        parsed_schedules = parse_manager_block_classic_only(raw_text)
        return [sch.to_dict() for sch in parsed_schedules]

    manager_speaker = find_manager_speaker(speaker_blocks)
    final_schedules: Dict[str, Schedule] = {}

    for speaker, content in speaker_blocks:
        if speaker == manager_speaker:
            parsed_schedules = parse_manager_block_classic_only(content)
            for sch in parsed_schedules:
                key = f"{sch.date}-{sch.time}-{sch.couple}"
                if key not in final_schedules:
                    final_schedules[key] = sch
                else:
                    if is_better_schedule(final_schedules[key], sch):
                        final_schedules[key] = sch

    return [sch.to_dict() for sch in final_schedules.values()]

def parse_schedules_ai_only(raw_text: str) -> List[Dict]:
    """AI/spaCy íŒŒì„œë§Œ ì‚¬ìš©"""
    if not nlp:
        return {"error": "spaCy NLP ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "success": False}

    try:
        current_year = datetime.now().year
        extracted_schedule = nlp_parse_flexible_format(raw_text, current_year)
        if extracted_schedule:
            return [extracted_schedule.to_dict()]
        else:
            return []
    except Exception as e:
        return {"error": f"AI íŒŒì„œ ì˜¤ë¥˜: {str(e)}", "success": False}

def parse_manager_block_classic_only(block_text: str) -> List[Schedule]:
    """í´ë˜ì‹ íŒ¨í„´ë§Œ ì‚¬ìš©í•˜ëŠ” parse_manager_block"""
    schedules = []
    current_year = datetime.now().year
    lines = [line.strip() for line in block_text.splitlines() if line.strip() and not line.startswith('---')]

    # Find all schedule start indices (line 1 of the 4-line core)
    start_indices = []
    for i, line in enumerate(lines):
        if is_valid_date(line):
            start_indices.append(i)
            clean_date = extract_date(line)
            if clean_date:
                lines[i] = clean_date

    # í´ë˜ì‹ ëª¨ë“œì—ì„œëŠ” NLP íŒŒì„œ í˜¸ì¶œ ì•ˆí•¨
    if not start_indices:
        return []

    for i, start_idx in enumerate(start_indices):
        end_idx = start_indices[i+1] if (i + 1) < len(start_indices) else len(lines)
        schedule_lines = lines[start_idx:end_idx]

        if len(schedule_lines) < 4:
            continue

        # Core 4-line block validation
        date, location, time, couple = schedule_lines[0], schedule_lines[1], schedule_lines[2], schedule_lines[3]
        if not (is_valid_date(date) and is_valid_time(time) and is_valid_couple(couple)):
            continue

        # ì‹ ë‘ì‹ ë¶€ ì´ë¦„ ë¶„ë¦¬ ì²˜ë¦¬
        separated_couple = separate_couple_names(couple)
        sch = Schedule(date=date, location=clean_location(location), time=time, couple=separated_couple)

        # Subtractive parsing on the rest of the lines
        remaining_lines = schedule_lines[4:]
        processed_indices = set()

        if remaining_lines:
            sch.manager = remaining_lines.pop(-1).strip()
            # Standardize contractor names
            if 'ê·¸ëœë“œ ë¸”ë‘' in sch.manager:
                sch.manager = sch.manager.replace('ê·¸ëœë“œ ë¸”ë‘', 'ê·¸ëœë“œë¸”ë‘')

        # First, check for contact number in the first line only (right after couple names)
        if remaining_lines:
            contact = parse_contact(remaining_lines[0])
            if contact:
                sch.contact = contact
                processed_indices.add(0)

        j = 0
        while j < len(remaining_lines):
            line = remaining_lines[j]
            is_known_pattern = False

            # Skip contact parsing since we already handled it above
            if j == 0 and sch.contact:
                is_known_pattern = True

            brand, album = parse_brand_album(line)
            if brand or album:
                if brand: sch.brand = brand
                if album: sch.album = album
                processed_indices.add(j); is_known_pattern = True

            # Extract photographer name by removing contact and role info
            name_part = re.sub(r'010[- .]?\d{4}[- .]?\d{4}', '', line).strip()
            name_part = re.sub(r'\([^)]*\)', '', name_part).strip()  # Remove parentheses content like (ë©”ì¸), (ì„œë¸Œ)
            name_part = re.sub(r'â€­|â€¬', '', name_part).strip()  # Remove invisible characters

            if is_valid_photographer_name(name_part):
                photographers = [name_part]
                processed_indices.add(j); is_known_pattern = True

                # Check next line for additional photographer
                if (j + 1) < len(remaining_lines):
                    next_line = remaining_lines[j+1]
                    next_name_part = re.sub(r'010[- .]?\d{4}[- .]?\d{4}', '', next_line).strip()
                    next_name_part = re.sub(r'\([^)]*\)', '', next_name_part).strip()
                    next_name_part = re.sub(r'â€­|â€¬', '', next_name_part).strip()

                    if is_valid_photographer_name(next_name_part):
                        photographers.append(next_name_part)
                        processed_indices.add(j + 1)
                        j += 1  # Skip next line since we processed it

                sch.photographer = ", ".join(photographers)
                is_known_pattern = True

            # Only mark as needs_review if line is not empty and not a known pattern
            # We'll handle comments content separately
            if not is_known_pattern and line.strip():
                sch.needs_review = True
                if not sch.review_reason:
                    sch.review_reason = "ì•Œ ìˆ˜ ì—†ëŠ” ë‚´ìš©"

            j += 1

        # Create comments from unprocessed lines
        sch.memo = "\n".join(remaining_lines[k] for k in range(len(remaining_lines)) if k not in processed_indices).strip()

        # If we have comments content, it means there were unprocessed lines
        # Reset needs_review to False since comments content is intentional
        if sch.memo:
            sch.needs_review = False
            sch.review_reason = ""

        # Mark for review if critical fields are missing
        missing_fields = []
        if not sch.brand: missing_fields.append("ë¸Œëœë“œ")
        if not sch.album: missing_fields.append("ì•¨ë²”")
        if not sch.photographer: missing_fields.append("ì‘ê°€")
        if not sch.manager: missing_fields.append("ê³„ì•½ì")

        if missing_fields:
            sch.needs_review = True
            sch.review_reason = f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {', '.join(missing_fields)}"

        # ì´¬ì˜ë‹¨ê°€ ìë™ ê³„ì‚° (í´ë˜ì‹ íŒŒì„œì—ì„œë„)
        if sch.brand and sch.album and sch.date:
            sch.price = calculate_price(sch.brand, sch.album, sch.date)

        schedules.append(sch)

        # í´ë˜ì‹ íŒ¨í„´ 1-3ë§Œ ì ìš©
        for line in lines:
            # íŒ¨í„´ 1: MMì›” DDì¼ HHì‹œMMë¶„ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€
            schedule_match = re.match(
                r'^(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2})ì‹œ(\d{1,2})ë¶„\s+(.+?)\s+([ê°€-í£]+)\s+([ê°€-í£]+)\s*-\s*([ê°€-í£]+)\s*ì‘ê°€',
                line
            )
            if schedule_match:
                month, day, hour, minute, location, groom, bride, photographer = schedule_match.groups()
                month, day, hour, minute = int(month), int(day), int(hour), int(minute)

                date = f"{current_year}.{month:02d}.{day:02d}"
                time = f"{hour:02d}:{minute:02d}"
                couple = f"{groom} {bride}"

                schedule = Schedule(
                    date=date, location=clean_location(location), time=time, couple=couple,
                    photographer=photographer, manager="", brand="", album="",
                    contact="", memo="", needs_review=True,
                    review_reason="ê°„ê²°í•œ í˜•ì‹: ë¸Œëœë“œ, ì•¨ë²”, ê³„ì•½ì ì •ë³´ ëˆ„ë½"
                )
                schedules.append(schedule)
                continue

            # íŒ¨í„´ 2: MMì›” DDì¼ HH:MMì‹œ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€ (ì½œë¡  í˜•íƒœ)
            schedule_match = re.match(
                r'^(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2}):(\d{2})ì‹œ\s+(.+?)\s+([ê°€-í£]+)\s+([ê°€-í£]+)\s*-\s*([ê°€-í£]+)\s*ì‘ê°€',
                line
            )
            if schedule_match:
                month, day, hour, minute, location, groom, bride, photographer = schedule_match.groups()
                month, day, hour, minute = int(month), int(day), int(hour), int(minute)

                date = f"{current_year}.{month:02d}.{day:02d}"
                time = f"{hour:02d}:{minute:02d}"
                couple = f"{groom} {bride}"

                schedule = Schedule(
                    date=date, location=clean_location(location), time=time, couple=couple,
                    photographer=photographer, manager="", brand="", album="",
                    contact="", memo="", needs_review=True,
                    review_reason="ê°„ê²°í•œ í˜•ì‹: ë¸Œëœë“œ, ì•¨ë²”, ê³„ì•½ì ì •ë³´ ëˆ„ë½"
                )
                schedules.append(schedule)
                continue

            # íŒ¨í„´ 3: MMì›” DDì¼ HHì‹œ ì¥ì†Œ ì‹ ë‘ ì‹ ë¶€ - ì‘ê°€ (ê¸°ë³¸ í˜•íƒœ)
            schedule_match = re.match(
                r'^(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2})ì‹œ\s+(.+?)\s+([ê°€-í£]+)\s+([ê°€-í£]+)\s*-\s*([ê°€-í£]+)\s*ì‘ê°€',
                line
            )
            if schedule_match:
                month, day, hour, location, groom, bride, photographer = schedule_match.groups()
                month, day, hour = int(month), int(day), int(hour)

                date = f"{current_year}.{month:02d}.{day:02d}"
                time = f"{hour:02d}:00"
                couple = f"{groom} {bride}"

                schedule = Schedule(
                    date=date, location=clean_location(location), time=time, couple=couple,
                    photographer=photographer, manager="", brand="", album="",
                    contact="", memo="", needs_review=True,
                    review_reason="ê°„ê²°í•œ í˜•ì‹: ë¸Œëœë“œ, ì•¨ë²”, ê³„ì•½ì ì •ë³´ ëˆ„ë½"
                )
                schedules.append(schedule)
                continue

    return schedules