"""
spaCy ê¸°ë°˜ ê³ ì„±ëŠ¥ NLP ìŠ¤ì¼€ì¤„ íŒŒì„œ
ì´ì „ scikit-learn ê¸°ë°˜ íŒŒì„œë³´ë‹¤ í›¨ì”¬ ê°•ë ¥í•œ ìì—°ì–´ ì²˜ë¦¬ ëŠ¥ë ¥ ì œê³µ
"""

import spacy
import re
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List
from dataclasses import dataclass

# spaCy í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ (ì „ì—­ìœ¼ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ)
try:
    nlp = spacy.load('ko_core_news_sm')
except OSError:
    print("âš ï¸  spaCy í•œêµ­ì–´ ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'python -m spacy download ko_core_news_sm' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    nlp = None

@dataclass
class ScheduleInfo:
    date: Optional[str] = None
    time: Optional[str] = None
    venue: Optional[str] = None
    couple: Optional[str] = None
    brand: Optional[str] = None
    photographer: Optional[str] = None
    contact: Optional[str] = None
    needs_review: bool = True
    review_reason: str = ""
    parser_used: str = "spacy_nlp"

def normalize_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì •ê·œí™”"""
    # ì´ëª¨í‹°ì½˜ ì œê±°
    text = re.sub(r'[ğŸ‰ğŸ“ğŸ‘°ğŸ»ğŸ¤µğŸ»ğŸ“¸ğŸ’•ğŸ’°â­ï¸]', '', text)

    # ì˜¤íƒ€ ìˆ˜ì •
    typo_fixes = {
        'ì•Œë²”': 'ì•¨ë²”',
        'ê·¸ë˜í”¼': 'ê·¸ë˜í”¼',
        'ì˜¤í›„3ì‹œ': 'ì˜¤í›„ 3ì‹œ',
        '2ì‹œë°˜': '2ì‹œ30ë¶„',
        'í•´ë³´ì´ì†Œ': 'í•´ë³´ì„¸ìš”'
    }

    for typo, correct in typo_fixes.items():
        text = text.replace(typo, correct)

    # ë„ì–´ì“°ê¸° ì •ê·œí™” (ë‚ ì§œ, ì‹œê°„ ê´€ë ¨)
    text = re.sub(r'(\d+ì›”)(\d+ì¼)', r'\1 \2', text)
    text = re.sub(r'(\d+ì¼)(í† ìš”ì¼|ì¼ìš”ì¼|ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼)', r'\1 \2', text)
    text = re.sub(r'(ì˜¤ì „|ì˜¤í›„)(\d+ì‹œ)', r'\1 \2', text)
    text = re.sub(r'(\d+ì‹œ)(\d+ë¶„)', r'\1\2', text)

    return text.strip()

def extract_entities_with_spacy(text: str) -> Dict[str, List[str]]:
    """spaCyë¥¼ ì‚¬ìš©í•œ ê°œì²´ëª… ì¶”ì¶œ"""
    if not nlp:
        return {}

    normalized_text = normalize_text(text)
    doc = nlp(normalized_text)

    entities = {
        'persons': [],      # PS (ì¸ëª…)
        'locations': [],    # LC (ì§€ëª…), OG (ì¡°ì§/ì¥ì†Œëª…)
        'dates': [],        # DT (ë‚ ì§œ)
        'times': [],        # TI (ì‹œê°„)
        'quantities': []    # QT (ìˆ˜ëŸ‰/ë²ˆí˜¸)
    }

    for ent in doc.ents:
        if ent.label_ == 'PS':  # ì¸ëª…
            entities['persons'].append(ent.text)
        elif ent.label_ in ['LC', 'OG']:  # ì§€ëª…, ì¡°ì§ëª…
            entities['locations'].append(ent.text)
        elif ent.label_ == 'DT':  # ë‚ ì§œ
            entities['dates'].append(ent.text)
        elif ent.label_ == 'TI':  # ì‹œê°„
            entities['times'].append(ent.text)
        elif ent.label_ == 'QT':  # ìˆ˜ëŸ‰
            entities['quantities'].append(ent.text)

    return entities

def extract_date_from_entities(entities: Dict[str, List[str]], text: str) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ ë° ì •ê·œí™”"""
    current_year = datetime.now().year

    # spaCyê°€ ì¸ì‹í•œ ë‚ ì§œ ê°œì²´ ìš°ì„  ì²˜ë¦¬
    for date_ent in entities.get('dates', []):
        # "ë‚´ì¼", "ì˜¤ëŠ˜", "ëª¨ë ˆ" ë“± ìƒëŒ€ì  ë‚ ì§œ
        if 'ë‚´ì¼' in date_ent:
            tomorrow = datetime.now() + timedelta(days=1)
            return tomorrow.strftime('%Y.%m.%d')
        elif 'ì˜¤ëŠ˜' in date_ent:
            return datetime.now().strftime('%Y.%m.%d')
        elif 'ëª¨ë ˆ' in date_ent:
            day_after_tomorrow = datetime.now() + timedelta(days=2)
            return day_after_tomorrow.strftime('%Y.%m.%d')

    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ (ë°±ì—…)
    date_patterns = [
        r'(\d{1,2})ì›”\s*(\d{1,2})ì¼',
        r'(\d{4})[.\-/](\d{1,2})[.\-/](\d{1,2})',
        r'(\d{1,2})[.\-/](\d{1,2})'
    ]

    for pattern in date_patterns:
        match = re.search(pattern, text)
        if match:
            if len(match.groups()) == 2:  # MMì›” DDì¼ í˜•íƒœ
                month, day = match.groups()
                return f"{current_year}.{int(month):02d}.{int(day):02d}"
            elif len(match.groups()) == 3:  # YYYY.MM.DD í˜•íƒœ
                year, month, day = match.groups()
                return f"{year}.{int(month):02d}.{int(day):02d}"

    # ìš”ì¼ ê¸°ë°˜ ë‚ ì§œ ì¶”ì¸¡
    weekdays = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
    for i, weekday in enumerate(weekdays):
        if weekday in text:
            # ê°€ì¥ ê°€ê¹Œìš´ í•´ë‹¹ ìš”ì¼ ì°¾ê¸°
            today = datetime.now()
            days_ahead = i - today.weekday()
            if days_ahead <= 0:  # ì´ë¯¸ ì§€ë‚¬ê±°ë‚˜ ì˜¤ëŠ˜ì´ë©´ ë‹¤ìŒ ì£¼
                days_ahead += 7
            target_date = today + timedelta(days=days_ahead)
            return target_date.strftime('%Y.%m.%d')

    return None

def extract_time_from_entities(entities: Dict[str, List[str]], text: str) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ì‹œê°„ ì¶”ì¶œ ë° ì •ê·œí™”"""
    # spaCyê°€ ì¸ì‹í•œ ì‹œê°„ ê°œì²´ ìš°ì„  ì²˜ë¦¬
    for time_ent in entities.get('times', []):
        # "ì˜¤í›„ 2ì‹œë°˜ì—" -> "14:30"
        time_match = re.search(r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ(\d{1,2}ë¶„|ë°˜)?', time_ent)
        if time_match:
            period, hour, minute_part = time_match.groups()
            hour = int(hour)

            if period == 'ì˜¤í›„' and hour != 12:
                hour += 12
            elif period == 'ì˜¤ì „' and hour == 12:
                hour = 0

            if minute_part == 'ë°˜':
                minute = 30
            elif minute_part and 'ë¶„' in minute_part:
                minute = int(minute_part.replace('ë¶„', ''))
            else:
                minute = 0

            return f"{hour:02d}:{minute:02d}"

    # ì •ê·œí‘œí˜„ì‹ ë°±ì—…
    time_patterns = [
        r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ\s*(\d{1,2})ë¶„',
        r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œë°˜',
        r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ',
        r'(\d{1,2}):(\d{2})'
    ]

    for pattern in time_patterns:
        match = re.search(pattern, text)
        if match:
            groups = match.groups()
            if len(groups) == 3 and groups[2]:  # ì˜¤ì „/ì˜¤í›„ + ì‹œ + ë¶„
                period, hour, minute = groups
                hour, minute = int(hour), int(minute)
            elif len(groups) == 2 and groups[0] in ['ì˜¤ì „', 'ì˜¤í›„']:  # ì˜¤ì „/ì˜¤í›„ + ì‹œë°˜
                period, hour = groups
                hour, minute = int(hour), 30
            elif len(groups) == 2 and groups[0].isdigit():  # HH:MM
                hour, minute = int(groups[0]), int(groups[1])
                period = None
            else:
                continue

            if period == 'ì˜¤í›„' and hour != 12:
                hour += 12
            elif period == 'ì˜¤ì „' and hour == 12:
                hour = 0

            return f"{hour:02d}:{minute:02d}"

    return None

def extract_venue_from_entities(entities: Dict[str, List[str]], text: str) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ì¥ì†Œ ì¶”ì¶œ"""
    # spaCyê°€ ì¸ì‹í•œ ì§€ëª…/ì¡°ì§ëª… ìš°ì„  ì‚¬ìš©
    for location in entities.get('locations', []):
        # í˜¸í…”, ì›¨ë”©í™€ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš° ìš°ì„ 
        if any(keyword in location for keyword in ['í˜¸í…”', 'ì›¨ë”©í™€', 'ì»¨ë²¤ì…˜', 'ì„¼í„°', 'í”Œë ˆì´ìŠ¤']):
            return location.replace('ì—ì„œ', '').replace('ì—', '').strip()

    # ì²« ë²ˆì§¸ ì§€ëª…/ì¡°ì§ëª… ì‚¬ìš©
    if entities.get('locations'):
        return entities['locations'][0].replace('ì—ì„œ', '').replace('ì—', '').strip()

    # ì •ê·œí‘œí˜„ì‹ ë°±ì—…
    venue_patterns = [
        r'([ê°€-í£\s]+(?:í˜¸í…”|ì›¨ë”©í™€|ì»¨ë²¤ì…˜|ì„¼í„°|í”Œë ˆì´ìŠ¤|ì±„í”Œ))',
        r'([ê°€-í£]+\s*[ê°€-í£]*(?:í˜¸í…”|ì›¨ë”©í™€))'
    ]

    for pattern in venue_patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()

    return None

def extract_couple_from_entities(entities: Dict[str, List[str]]) -> Optional[str]:
    """ê°œì²´ëª…ì—ì„œ ì‹ ë‘ì‹ ë¶€ ì¶”ì¶œ"""
    persons = entities.get('persons', [])
    if len(persons) >= 2:
        # ë‘ ëª… ì´ìƒì˜ ì¸ëª…ì´ ìˆìœ¼ë©´ ì‹ ë‘ì‹ ë¶€ë¡œ ê°„ì£¼
        return ' '.join(persons[:2])
    elif len(persons) == 1:
        return persons[0]

    return None

def is_meaningful_schedule_spacy(text: str, entities: Dict[str, List[str]]) -> bool:
    """spaCy ê¸°ë°˜ ì˜ë¯¸ìˆëŠ” ìŠ¤ì¼€ì¤„ íŒë‹¨"""
    # ë…¸ì´ì¦ˆ íŒ¨í„´ (ì·¨ì†Œ, ë¬¸ì˜, ì¼ë°˜ì ì¸ ëŒ€í™”)
    noise_patterns = [
        r'ì·¨ì†Œ', r'ì£„ì†¡', r'ë‹¤ì‹œ ì—°ë½', r'ë¬¸ì˜.*ë“œë ¤', r'í˜¹ì‹œë‚˜',
        r'ê°€ëŠ¥í•œ ë‚ ', r'ëŒ€ëµì ì¸', r'ì–¼ë§ˆì¸ì§€', r'ë¹„ìš©.*ê¶ê¸ˆ'
    ]

    for pattern in noise_patterns:
        if re.search(pattern, text):
            return False

    # í•µì‹¬ ìŠ¤ì¼€ì¤„ ìš”ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸
    has_date = bool(entities.get('dates')) or any(keyword in text for keyword in ['ë‚´ì¼', 'ì˜¤ëŠ˜', 'ì¼ìš”ì¼', 'í† ìš”ì¼', 'ì›”ìš”ì¼'])
    has_time = bool(entities.get('times')) or bool(re.search(r'\d+ì‹œ', text))
    has_venue = bool(entities.get('locations'))

    # ìµœì†Œ 1ê°œ ì´ìƒì˜ í•µì‹¬ ìš”ì†Œê°€ ìˆì–´ì•¼ ì˜ë¯¸ìˆëŠ” ìŠ¤ì¼€ì¤„ (ê¸°ì¤€ ì™„í™”)
    core_elements = sum([has_date, has_time, has_venue])

    return core_elements >= 1

def parse_schedule_with_spacy(text: str) -> Optional[ScheduleInfo]:
    """spaCyë¥¼ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ ìŠ¤ì¼€ì¤„ íŒŒì‹±"""
    if not nlp:
        return None

    # í…ìŠ¤íŠ¸ ì •ê·œí™”
    normalized_text = normalize_text(text)

    # spaCyë¡œ ê°œì²´ëª… ì¶”ì¶œ
    entities = extract_entities_with_spacy(normalized_text)

    # ì˜ë¯¸ìˆëŠ” ìŠ¤ì¼€ì¤„ì¸ì§€ íŒë‹¨
    if not is_meaningful_schedule_spacy(normalized_text, entities):
        return None

    # ê° ìš”ì†Œ ì¶”ì¶œ
    schedule = ScheduleInfo()
    schedule.date = extract_date_from_entities(entities, normalized_text)
    schedule.time = extract_time_from_entities(entities, normalized_text)
    schedule.venue = extract_venue_from_entities(entities, normalized_text)
    schedule.couple = extract_couple_from_entities(entities)

    # ë¸Œëœë“œ/ì•¨ë²” ì¶”ì¶œ (ì •ê·œí‘œí˜„ì‹)
    brand_patterns = [
        r'ì•¨ë²”[:\s]*([ê°€-í£A-Za-z\s\-]+)',
        r'ë¸Œëœë“œ[:\s]*([ê°€-í£A-Za-z\s\-]+)',
        r'(ê·¸ë˜í”¼|Kì„¸ë¸ìŠ¤|ë¹„ì„¸ë¸ìŠ¤|ì—ì´í”„ë¦¬ë¯¸ì—„|ì„¸ì»¨ë“œí”Œë¡œìš°)'
    ]

    for pattern in brand_patterns:
        match = re.search(pattern, normalized_text)
        if match:
            schedule.brand = match.group(1).strip()
            break

    # ê²€í†  í•„ìš”ì„± íŒë‹¨
    missing_elements = []
    if not schedule.date:
        missing_elements.append('ë‚ ì§œ')
    if not schedule.time:
        missing_elements.append('ì‹œê°„')
    if not schedule.venue:
        missing_elements.append('ì¥ì†Œ')

    if missing_elements:
        schedule.needs_review = True
        schedule.review_reason = f"ëˆ„ë½ëœ ì •ë³´: {', '.join(missing_elements)}"
    else:
        schedule.needs_review = False
        schedule.review_reason = ""

    # ìµœì†Œí•œ ë‚ ì§œë‚˜ ì‹œê°„ ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
    if not schedule.date and not schedule.time:
        return None

    return schedule

def test_spacy_parser():
    """spaCy íŒŒì„œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    test_cases = [
        "ë‚´ì¼ ì˜¤í›„3ì‹œ ë¡¯ë°í˜¸í…”ë¶€ì‚°ì—ì„œ ì´¬ì˜ìˆëŠ”ë° ê¹€ë¯¼ìˆ˜ ë°•ì§€ì›ì”¨ ê°€ëŠ¥í•˜ì‹ ê°€ìš”??",
        "11ì›”5ì¼í† ìš”ì¼ì˜¤ì „11ì‹œ30ë¶„ë¶€ì‚°ë§ˆë¦¬ë‚˜ë² ì´101ì›¨ë”©í™€",
        "ì´ë²ˆì£¼ ì¼ìš”ì¼ ì˜¤í›„ 2ì‹œë°˜ì— ê¹€í•´ ê°€ì•¼ì»¨ë²¤ì…˜ì„¼í„°ì—ì„œ ì´¬ì˜ í•œ ë²ˆ í•´ë³´ì´ì†Œ",
        "ğŸ‰ 12ì›” 1ì¼ (í† ) ì˜¤í›„ 1ì‹œ ğŸ‰ ğŸ“ ë¶€ì‚° íŒŒë¼ë‹¤ì´ìŠ¤í˜¸í…” ê·¸ëœë“œë³¼ë£¸",
        "ì£„ì†¡í•©ë‹ˆë‹¤ ë‚´ì¼ ì´¬ì˜ ì·¨ì†Œí•˜ê²Œ ëì–´ìš”ã… ã… ",
        "í˜¹ì‹œë‚˜ í•´ì„œ ì—°ë½ë“œë ¤ë´…ë‹ˆë‹¤ 12ì›” ì¤‘ì— ì›¨ë”©ì´¬ì˜ ê°€ëŠ¥í•œ ë‚ ì´ ìˆë‚˜ìš”?"
    ]

    # Test functionality without printing sensitive data
    for test_text in test_cases:
        result = parse_schedule_with_spacy(test_text)

if __name__ == "__main__":
    test_spacy_parser()